"""
åœºæ™¯åˆ†å‰²å™¨ - å°†æ–‡æ¡ˆåˆ†å‰²ä¸ºå¤šä¸ªåœºæ™¯åˆ†é•œ
å¯¹åº”åŸå·¥ä½œæµNode_1165778é…ç½®
"""
import asyncio
import json
import time
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import logging
from dataclasses import dataclass

from core.config_manager import ConfigManager, ModelConfig
from utils.file_manager import FileManager
from utils.enhanced_llm_manager import EnhancedLLMManager

@dataclass
class Scene:
    """å•ä¸ªåœºæ™¯"""
    sequence: int              # åœºæ™¯åºå·
    content: str              # åœºæ™¯å†…å®¹æ–‡æœ¬
    image_prompt: str         # å›¾åƒæç¤ºè¯ (æ–‡ç”Ÿå›¾ç”¨)
    video_prompt: str         # è§†é¢‘æç¤ºè¯ (å›¾ç”Ÿè§†é¢‘ç”¨)
    duration_seconds: float   # æ—¶é•¿ï¼ˆç§’ï¼‰
    animation_type: str       # åŠ¨ç”»ç±»å‹
    subtitle_text: str        # å­—å¹•æ–‡æœ¬
    
@dataclass
class SceneSplitRequest:
    """åœºæ™¯åˆ†å‰²è¯·æ±‚"""
    script_content: str       # åŸå§‹æ–‡æ¡ˆå†…å®¹
    language: str            # è¯­è¨€ä»£ç 
    use_coze_rules: bool = True  # ä½¿ç”¨åŸCozeå·¥ä½œæµåˆ†å‰²è§„åˆ™
    target_scene_count: int = 8  # ç›®æ ‡åœºæ™¯æ•°é‡ï¼ˆä»…åœ¨use_coze_rules=Falseæ—¶ä½¿ç”¨ï¼‰
    scene_duration: float = 3.0  # æ¯ä¸ªåœºæ™¯æ—¶é•¿ï¼ˆç§’ï¼‰

@dataclass
class SceneSplitResult:
    """åœºæ™¯åˆ†å‰²ç»“æœ"""
    scenes: List[Scene]       # åœºæ™¯åˆ—è¡¨
    total_duration: float     # æ€»æ—¶é•¿
    language: str            # è¯­è¨€
    original_script: str     # åŸå§‹æ–‡æ¡ˆ
    split_time: float        # åˆ†å‰²è€—æ—¶
    model_used: str          # ä½¿ç”¨çš„æ¨¡å‹

class SceneSplitter:
    """
    åœºæ™¯åˆ†å‰²å™¨
    
    åŸºäºåŸCozeå·¥ä½œæµNode_1165778é…ç½®ï¼š
    - æ¨¡å‹: DeepSeek-V3
    - Temperature: 0.8
    - Max tokens: 8192
    - å°†æ–‡æ¡ˆåˆ†å‰²ä¸º8ä¸ªåœºæ™¯ï¼Œæ¯ä¸ªåœºæ™¯3ç§’
    """
    
    def __init__(self, config_manager: ConfigManager, 
                 file_manager: FileManager):
        self.config = config_manager
        self.file_manager = file_manager
        self.logger = logging.getLogger('story_generator.content')
        
        # æ”¯æŒçš„è¯­è¨€ - å¿…é¡»åœ¨åŠ è½½æç¤ºè¯æ¨¡æ¿ä¹‹å‰è®¾ç½®
        self.supported_languages = self.config.get_supported_languages()
        
        # è·å–LLMé…ç½®
        self.llm_config = self.config.get_llm_config('scene_splitting')
        
        # å›¾åƒæç¤ºè¯ç”Ÿæˆå™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–é¿å…å¾ªç¯å¯¼å…¥ï¼‰
        self._image_prompt_generator = None
        
        # ä½¿ç”¨ç»Ÿä¸€çš„å¢å¼ºLLMç®¡ç†å™¨
        self.llm_manager = EnhancedLLMManager(config_manager)
        self.logger.info("âœ… ä½¿ç”¨å¢å¼ºLLMç®¡ç†å™¨ (ç»Ÿä¸€æ¶æ„)")
        
        # åŠ è½½æç¤ºè¯æ¨¡æ¿
        self._load_prompt_templates()
    
    
    def _get_image_prompt_generator(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å›¾åƒæç¤ºè¯ç”Ÿæˆå™¨"""
        if self._image_prompt_generator is None:
            from .image_prompt_generator import ImagePromptGenerator
            self._image_prompt_generator = ImagePromptGenerator(
                self.config, self.file_manager
            )
            self.logger.info("Initialized image prompt generator")
        return self._image_prompt_generator
    
    async def _generate_image_prompts_for_scenes(self, scenes: List[Scene], request: SceneSplitRequest) -> List[Scene]:
        """
        ä½¿ç”¨ä¸“é—¨çš„å›¾åƒæç¤ºè¯ç”Ÿæˆå™¨ä¸ºåœºæ™¯ç”Ÿæˆé«˜è´¨é‡å›¾åƒæç¤ºè¯
        
        Args:
            scenes: åŸå§‹åœºæ™¯åˆ—è¡¨
            request: åœºæ™¯åˆ†å‰²è¯·æ±‚
        
        Returns:
            List[Scene]: æ›´æ–°åçš„åœºæ™¯åˆ—è¡¨
        """
        try:
            # è·å–å›¾åƒæç¤ºè¯ç”Ÿæˆå™¨
            image_prompt_generator = self._get_image_prompt_generator()
            
            # åˆ›å»ºå›¾åƒæç¤ºè¯ç”Ÿæˆè¯·æ±‚
            from .image_prompt_generator import ImagePromptRequest
            prompt_request = ImagePromptRequest(
                scenes=scenes,
                language=request.language,
                style="ancient_horror"
            )
            
            # ä½¿ç”¨LLMç”Ÿæˆå›¾åƒæç¤ºè¯
            self.logger.info(f"Generating image prompts for {len(scenes)} scenes using LLM...")
            prompt_result = await image_prompt_generator.generate_image_prompts_async(prompt_request)
            
            self.logger.info(f"Successfully generated {len(prompt_result.scenes)} image prompts in {prompt_result.generation_time:.2f}s")
            
            return prompt_result.scenes
            
        except Exception as e:
            self.logger.error(f"Failed to generate image prompts using LLM: {e}")
            # ä¸å†ä½¿ç”¨fallbackæœºåˆ¶ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸ä»¥æš´éœ²é—®é¢˜
            raise Exception(f"LLM image prompt generation failed: {e}. No fallback methods provided.")
    
    def _load_prompt_templates(self):
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        self.prompt_templates = {}
        prompts_dir = Path("config/prompts")
        
        for lang in self.supported_languages:
            lang_dir = prompts_dir / lang
            if lang_dir.exists():
                # åŠ è½½åœºæ™¯åˆ†å‰²æç¤ºè¯
                scene_prompt_file = lang_dir / "scene_splitting.txt"
                if scene_prompt_file.exists():
                    try:
                        content = self.file_manager.load_text(scene_prompt_file)
                        if content:
                            self.prompt_templates[lang] = content
                            self.logger.debug(f"Loaded scene splitting prompt for language: {lang}")
                    except Exception as e:
                        self.logger.error(f"Failed to load scene splitting prompt for {lang}: {e}")
        
        if not self.prompt_templates:
            self.logger.warning("No scene splitting prompts loaded, using default templates")
            self._create_default_prompts()
    
    def _create_default_prompts(self):
        """åˆ›å»ºé»˜è®¤æç¤ºè¯æ¨¡æ¿"""
        self.prompt_templates = {
            'zh': """# è§’è‰²
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘åˆ†é•œå¸ˆï¼Œè´Ÿè´£å°†å†å²æ•…äº‹æ–‡æ¡ˆåˆ†å‰²ä¸ºé€‚åˆè§†é¢‘åˆ¶ä½œçš„å¤šä¸ªåœºæ™¯ã€‚

## æŠ€èƒ½
### æŠ€èƒ½1ï¼šåœºæ™¯åˆ†å‰²
1. å°†è¾“å…¥çš„å†å²æ•…äº‹æ–‡æ¡ˆåˆ†å‰²ä¸º8ä¸ªç‹¬ç«‹åœºæ™¯
2. æ¯ä¸ªåœºæ™¯åº”è¯¥åŒ…å«å®Œæ•´çš„æ•…äº‹ç‰‡æ®µï¼Œæ—¶é•¿çº¦3ç§’
3. ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆè¯¦ç»†çš„è‹±æ–‡å›¾åƒæè¿°æç¤ºè¯ï¼Œå¿…é¡»åŒ…å«å…·ä½“çš„äººç‰©ã€æœè£…ã€ç¯å¢ƒã€åŠ¨ä½œç­‰ç»†èŠ‚
4. ç¡®ä¿åœºæ™¯ä¹‹é—´çš„è¿è´¯æ€§å’Œé€»è¾‘æ€§
5. ç”Ÿæˆé€‚åˆçš„å­—å¹•æ–‡æœ¬

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œ**æ³¨æ„image_promptå¿…é¡»ç”¨è‹±æ–‡ç”Ÿæˆ**ï¼š

```json
{
  "scenes": [
    {
      "sequence": 1,
      "content": "åœºæ™¯1çš„æ•…äº‹å†…å®¹",
      "image_prompt": "Ancient China, Emperor Zhu Yuanzhang wearing tattered cloth robes, gaunt and weary face, begging in desolate fields, background of post-war ruins, dim tones, historical realistic style, ancient horror atmosphere, white background, traditional clothing, high definition, high contrast, low saturation colors",
      "duration_seconds": 3.0,
      "animation_type": "è½»å¾®æ”¾å¤§",
      "subtitle_text": "åœºæ™¯1çš„å­—å¹•æ–‡æœ¬"
    }
  ]
}
```

## é‡è¦æé†’ - å›¾åƒæç¤ºè¯è‹±æ–‡åŒ–è¦æ±‚
- **image_promptå­—æ®µå¿…é¡»ç”¨è‹±æ–‡ç”Ÿæˆ**ï¼Œè¿™æ ·AIç»˜å›¾æ•ˆæœæ›´å¥½
- **æ¯ä¸ªåœºæ™¯çš„å›¾åƒæç¤ºè¯å¿…é¡»ä¸åŒä¸”å…·ä½“**ï¼Œé¿å…ç”Ÿæˆç›¸åŒå›¾åƒ
- è‹±æ–‡æç¤ºè¯å¿…é¡»æ ¹æ®åœºæ™¯å†…å®¹ç”Ÿæˆå…·ä½“æè¿°ï¼ŒåŒ…å«ï¼š
  * Specific character appearance and actions (å…·ä½“äººç‰©å¤–è²Œå’ŒåŠ¨ä½œ)
  * Detailed clothing and decorations (è¯¦ç»†æœè£…å’Œè£…é¥°) 
  * Clear environment and background (æ˜ç¡®ç¯å¢ƒå’ŒèƒŒæ™¯)
  * Historical period characteristics (å†å²æ—¶ä»£ç‰¹å¾)
  * Different camera angles and perspectives (ä¸åŒçš„é•œå¤´è§’åº¦å’Œè§†è§’)
  * Unique scene elements for each scene (æ¯ä¸ªåœºæ™¯çš„ç‹¬ç‰¹å…ƒç´ )
- ç»Ÿä¸€æ·»åŠ æ ·å¼è¦æ±‚ï¼šancient horror style, white background, dim colors, twilight atmosphere, traditional clothing, rough lines, character close-up, high definition, high contrast, low saturation colors, shallow depth of field
- ç¤ºä¾‹æ­£ç¡®æ ¼å¼ï¼š"Ancient China Warring States period, Emperor Qin Shi Huang wearing black dragon robe, stern and majestic expression, standing in Xianyang Palace hall, ornate palace architecture background, dim lighting, solemn atmosphere, ancient horror style, high definition"
- ç»å¯¹ä¸èƒ½ä½¿ç”¨ï¼š"å†å²åœºæ™¯1"ã€"åœºæ™¯æè¿°"ã€"å›¾åƒæç¤º"ç­‰ä¸­æ–‡å ä½ç¬¦
- **ç¡®ä¿æ¯ä¸ªåœºæ™¯çš„æè¿°éƒ½åŒ…å«ä¸åŒçš„ç»†èŠ‚ã€è§’åº¦æˆ–å…ƒç´ ï¼Œé¿å…é‡å¤**

## é™åˆ¶
1. å¿…é¡»è¾“å‡ºæ°å¥½8ä¸ªåœºæ™¯
2. æ¯ä¸ªåœºæ™¯æ—¶é•¿å›ºå®šä¸º3ç§’
3. å›¾åƒæè¿°è¦è¯¦ç»†ä¸”ç¬¦åˆå†å²èƒŒæ™¯ï¼Œç”¨è‹±æ–‡è¡¨è¾¾åŒ…å«å…·ä½“ç»†èŠ‚
4. å­—å¹•æ–‡æœ¬ä¿æŒä¸­æ–‡ï¼Œç®€æ´æ˜äº†

ç°åœ¨è¯·åˆ†å‰²ä»¥ä¸‹å†å²æ•…äº‹æ–‡æ¡ˆï¼š

{{script_content}}""",

            'en': """# Role
You are a professional video storyboard artist responsible for splitting historical story scripts into multiple scenes suitable for video production.

## Skills
### Skill 1: Scene Splitting
1. Split the input historical story script into 8 independent scenes
2. Each scene should contain a complete story segment, lasting about 3 seconds
3. Generate detailed English image description prompts for each scene, including specific details about characters, clothing, environment, and actions
4. Ensure coherence and logic between scenes
5. Generate suitable subtitle text

## Output Format
Please output strictly in the following JSON format with **English image prompts**:

```json
{
  "scenes": [
    {
      "sequence": 1,
      "content": "Story content for scene 1",
      "image_prompt": "Ancient China, Emperor Zhu Yuanzhang wearing tattered cloth robes, gaunt and weary face, begging in desolate fields, background of post-war ruins, dim tones, historical realistic style, ancient horror atmosphere, white background, traditional clothing, high definition, high contrast, low saturation colors", 
      "duration_seconds": 3.0,
      "animation_type": "slight zoom",
      "subtitle_text": "Subtitle text for scene 1"
    }
  ]
}
```

## Important Notes - English Image Prompt Requirements
- **image_prompt must be in English** for optimal AI image generation results
- English prompts must include specific scene-based descriptions with:
  * Specific character appearance and actions
  * Detailed clothing and decorations
  * Clear environment and background
  * Historical period characteristics
  * Artistic style elements
- Always include style requirements: ancient horror style, white background, dim colors, twilight atmosphere, traditional clothing, rough lines, character close-up, high definition, high contrast, low saturation colors, shallow depth of field
- Example format: "Ancient China Warring States period, Emperor Qin Shi Huang wearing black dragon robe, stern and majestic expression, standing in Xianyang Palace hall, ornate palace architecture background, dim lighting, solemn atmosphere, ancient horror style, high definition"
- Never use generic placeholders like "Historical Scene 1", "Scene Description"

## Constraints
1. Must output exactly 8 scenes
2. Each scene duration is fixed at 3 seconds
3. Image descriptions must be detailed, historically accurate, and in English
4. Subtitle text should be concise and clear

Now please split the following historical story script:

{{script_content}}""",

            'es': """# Rol
Eres un artista profesional de storyboard de video responsable de dividir guiones de historias histÃ³ricas en mÃºltiples escenas adecuadas para la producciÃ³n de video.

## Habilidades
### Habilidad 1: DivisiÃ³n de Escenas
1. Dividir el guiÃ³n de historia histÃ³rica de entrada en 8 escenas independientes
2. Cada escena debe contener un segmento completo de la historia, que dure unos 3 segundos
3. Generar indicaciones detalladas en inglÃ©s para descripciÃ³n de imagen para cada escena
4. Asegurar coherencia y lÃ³gica entre escenas
5. Generar texto de subtÃ­tulos adecuado

## Formato de Salida
Por favor, genera estrictamente en el siguiente formato JSON con **indicaciones de imagen en inglÃ©s**:

```json
{
  "scenes": [
    {
      "sequence": 1,
      "content": "Contenido de la historia para la escena 1",
      "image_prompt": "Ancient China, Emperor Zhu Yuanzhang wearing tattered cloth robes, gaunt and weary face, begging in desolate fields, background of post-war ruins, dim tones, historical realistic style, ancient horror atmosphere, white background, traditional clothing, high definition, high contrast, low saturation colors",
      "duration_seconds": 3.0,
      "animation_type": "zoom ligero", 
      "subtitle_text": "Texto de subtÃ­tulo para la escena 1"
    }
  ]
}
```

## Notas Importantes - Requisitos de Indicaciones de Imagen en InglÃ©s
- **image_prompt debe estar en inglÃ©s** para obtener mejores resultados de generaciÃ³n de imÃ¡genes AI
- Las indicaciones en inglÃ©s deben incluir descripciones especÃ­ficas basadas en la escena con:
  * Apariencia especÃ­fica del personaje y acciones
  * Ropa detallada y decoraciones
  * Entorno claro y fondo
  * CaracterÃ­sticas del perÃ­odo histÃ³rico
  * Elementos de estilo artÃ­stico
- Incluir siempre requisitos de estilo: ancient horror style, white background, dim colors, twilight atmosphere, traditional clothing, rough lines, character close-up, high definition, high contrast, low saturation colors, shallow depth of field
- Formato de ejemplo: "Ancient China Warring States period, Emperor Qin Shi Huang wearing black dragon robe, stern and majestic expression, standing in Xianyang Palace hall, ornate palace architecture background, dim lighting, solemn atmosphere, ancient horror style, high definition"
- Nunca usar marcadores genÃ©ricos como "Historical Scene 1", "Scene Description"

## Restricciones
1. Debe generar exactamente 8 escenas
2. La duraciÃ³n de cada escena es fija en 3 segundos
3. Las descripciones de imagen deben ser detalladas, histÃ³ricamente precisas, y en inglÃ©s
4. El texto del subtÃ­tulo debe ser conciso y claro

Ahora por favor divide el siguiente guiÃ³n de historia histÃ³rica:

{{script_content}}"""
        }
    
    async def split_scenes_async(self, request: SceneSplitRequest) -> SceneSplitResult:
        """
        å¼‚æ­¥åˆ†å‰²åœºæ™¯
        
        Args:
            request: åœºæ™¯åˆ†å‰²è¯·æ±‚
        
        Returns:
            SceneSplitResult: åˆ†å‰²ç»“æœ
        """
        start_time = time.time()
        
        try:
            # ç¼“å­˜å·²ç¦ç”¨ - æ¯æ¬¡éƒ½ç”Ÿæˆæ–°å†…å®¹
            
            # éªŒè¯è¯·æ±‚
            if request.language not in self.supported_languages:
                raise ValueError(f"Unsupported language: {request.language}")
            
            # å¼ºåˆ¶ä½¿ç”¨LLMåˆ†å‰² - ä¸å†ä½¿ç”¨coze_rules fallback
            if request.language not in self.prompt_templates:
                raise ValueError(f"No prompt template for language: {request.language}")
            
            # æ„å»ºæç¤ºè¯
            prompt_template = self.prompt_templates[request.language]
            prompt = prompt_template.replace('{{script_content}}', request.script_content)
            
            # è°ƒç”¨LLM API
            self.logger.info(f"Splitting scenes for {request.language} script...")
            
            response = await self._call_llm_api(prompt)
            
            if not response:
                raise ValueError("Empty response from LLM")
            
            # æ£€æŸ¥å“åº”ç±»å‹ - å¤„ç†å¢å¼ºLLMç®¡ç†å™¨ç›´æ¥è¿”å›Sceneåˆ—è¡¨çš„æƒ…å†µ
            if isinstance(response, list):
                # å¢å¼ºLLMç®¡ç†å™¨æˆåŠŸè¿”å›äº†Sceneåˆ—è¡¨
                scenes = response
                self.logger.info(f"âœ… ç›´æ¥è·å¾—ç»“æ„åŒ–åœºæ™¯åˆ—è¡¨: {len(scenes)} scenes")
            else:
                # ä¼ ç»Ÿå­—ç¬¦ä¸²å“åº”ï¼Œéœ€è¦è§£æ
                self.logger.debug(f"LLM Response length: {len(response)}")
                scenes = self._parse_scenes_response(response, request)
            
            # è®°å½•å®é™…ç”Ÿæˆçš„åœºæ™¯æ•°é‡ - ä¸è®¾ç½®ä»»ä½•é™åˆ¶ï¼Œå®Œå…¨åŸºäºå†…å®¹è‡ªç„¶åˆ†å‰²
            self.logger.info(f"Generated {len(scenes)} scenes based on content structure")
            
            # åªåšåŸºæœ¬çš„æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
            if len(scenes) == 0:
                raise ValueError("No scenes were generated from the script")
            
            # æä¾›ä¿¡æ¯æ€§æç¤ºï¼Œä½†ä¸é™åˆ¶åœºæ™¯æ•°é‡
            if len(scenes) == 1:
                self.logger.info("Single scene generated - this is fine for short content")
            elif len(scenes) > 20:
                self.logger.info(f"Large number of scenes ({len(scenes)}) - this suggests rich, detailed content")
            
            # ä½¿ç”¨ä¸“é—¨çš„å›¾åƒæç¤ºè¯ç”Ÿæˆå™¨ç”Ÿæˆé«˜è´¨é‡æç¤ºè¯
            scenes = await self._generate_image_prompts_for_scenes(scenes, request)
            
            # è®¡ç®—æ€»æ—¶é•¿
            total_duration = sum(scene.duration_seconds for scene in scenes)
            
            # åˆ›å»ºç»“æœå¯¹è±¡
            result = SceneSplitResult(
                scenes=scenes,
                total_duration=total_duration,
                language=request.language,
                original_script=request.script_content,
                split_time=time.time() - start_time,
                model_used=self.llm_config.name
            )
            
            # ç¼“å­˜ç»“æœ
            cache_data = {
                'scenes': [self._scene_to_dict(scene) for scene in scenes],
                'total_duration': result.total_duration,
                'language': result.language,
                'original_script': result.original_script,
                'model_used': result.model_used
            }
            
            # ç¼“å­˜å·²ç¦ç”¨
            
            # è®°å½•æ—¥å¿—
            logger = self.config.get_logger('story_generator')
            logger.info(f"Content generation - Type: scene_splitting, Language: {request.language}, "
                       f"Input: {len(request.script_content)} chars, Output: {len(json.dumps(cache_data, ensure_ascii=False))} chars, "
                       f"Time: {result.split_time:.2f}s")
            
            self.logger.info(f"Split scenes successfully: {len(scenes)} scenes, {total_duration:.1f}s total duration")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"Scene splitting failed: {e}")
            
            # è®°å½•é”™è¯¯æ—¥å¿—
            logger = self.config.get_logger('story_generator')
            logger.error(f"Content generation failed - Type: scene_splitting, Language: {request.language}, "
                        f"Input: {len(request.script_content)} chars, Time: {processing_time:.2f}s")
            
            raise
    
    def _split_prompt(self, prompt: str) -> tuple[str, str]:
        """å°†å•ä¸ªpromptåˆ†ç¦»ä¸ºsystem_promptå’Œuser_prompt"""
        
        # å°è¯•ä»promptä¸­æ‰¾åˆ°åˆé€‚çš„åˆ†å‰²ç‚¹
        lines = prompt.split('\n')
        
        # æŸ¥æ‰¾æŒ‡ç¤ºç”¨æˆ·è¾“å…¥å¼€å§‹çš„æ ‡å¿—
        user_start_markers = ['æ•…äº‹å†…å®¹:', 'è¯·åˆ†å‰²ä»¥ä¸‹æ•…äº‹:', 'è„šæœ¬å†…å®¹:', 'æ•…äº‹:', 'å†…å®¹:']
        
        system_lines = []
        user_lines = []
        found_user_start = False
        
        for line in lines:
            line_clean = line.strip()
            if not found_user_start:
                # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°ç”¨æˆ·å†…å®¹å¼€å§‹æ ‡å¿—
                for marker in user_start_markers:
                    if marker in line_clean:
                        found_user_start = True
                        user_lines.append(line)
                        break
                if not found_user_start:
                    system_lines.append(line)
            else:
                user_lines.append(line)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„åˆ†å‰²ç‚¹ï¼Œé‡‡ç”¨ç®€å•çš„ç­–ç•¥
        if not user_lines:
            # å°†å‰80%ä½œä¸ºç³»ç»Ÿæç¤ºè¯ï¼Œå20%ä½œä¸ºç”¨æˆ·è¾“å…¥
            split_point = int(len(lines) * 0.8)
            system_lines = lines[:split_point]
            user_lines = lines[split_point:]
        
        system_prompt = '\n'.join(system_lines).strip()
        user_prompt = '\n'.join(user_lines).strip()
        
        # ç¡®ä¿è‡³å°‘æœ‰åŸºæœ¬çš„ç³»ç»Ÿæç¤ºè¯
        if not system_prompt:
            system_prompt = "ä½ æ˜¯ä¸“ä¸šçš„æ•…äº‹åœºæ™¯åˆ†å‰²ä¸“å®¶ã€‚å°†è¾“å…¥çš„æ•…äº‹åˆ†å‰²ä¸ºå¤šä¸ªåœºæ™¯ï¼Œæ¯ä¸ªåœºæ™¯3ç§’é’Ÿã€‚"
        
        # ç¡®ä¿è‡³å°‘æœ‰ç”¨æˆ·è¾“å…¥
        if not user_prompt:
            user_prompt = prompt
        
        return system_prompt, user_prompt
    
    async def _call_llm_api(self, prompt: str) -> str:
        """
        è°ƒç”¨LLM API - ä¼˜å…ˆä½¿ç”¨å¢å¼ºLLMç®¡ç†å™¨ (OpenAI Structured Output + å¤šå±‚é™çº§)
        
        Args:
            prompt: æç¤ºè¯
        
        Returns:
            str or List[Scene]: LLMå“åº” æˆ– ç»“æ„åŒ–Sceneåˆ—è¡¨
        """
        try:
            # ä¼˜å…ˆå°è¯•å¢å¼ºLLMç®¡ç†å™¨ (OpenAI Structured Output + å¤šå±‚é™çº§)
            # ä½¿ç”¨ç»Ÿä¸€çš„å¢å¼ºLLMç®¡ç†å™¨
            try:
                self.logger.info("ğŸš€ ä½¿ç”¨å¢å¼ºLLMç®¡ç†å™¨ (OpenAI GPT-4.1 + Structured Output)")
                
                # ä»promptä¸­åˆ†ç¦»ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯
                system_prompt, user_prompt = self._split_prompt(prompt)
                
                structured_output = await self.llm_manager.generate_structured_output(
                    task_type='scene_splitting',
                    system_prompt=system_prompt,
                    user_prompt=user_prompt,
                    max_retries=2
                )
                
                if hasattr(structured_output, 'scenes') and structured_output.scenes:
                    # è½¬æ¢ä¸ºåŸæœ‰çš„Sceneå¯¹è±¡æ ¼å¼
                    scenes = []
                    for scene_data in structured_output.scenes:
                        scene = Scene(
                            sequence=scene_data.sequence,
                            content=scene_data.content,
                            image_prompt="",  # åç»­ç”Ÿæˆ
                            video_prompt="", # åç»­ç”Ÿæˆ  
                            duration_seconds=scene_data.duration,
                            animation_type="center_zoom_in",
                            subtitle_text=scene_data.content
                        )
                        scenes.append(scene)
                    
                    self.logger.info(f"âœ… å¢å¼ºLLMç®¡ç†å™¨æˆåŠŸ: {len(scenes)} scenes (OpenAI GPT-4.1)")
                    return scenes
                        
            except Exception as e:
                self.logger.warning(f"âš ï¸ å¢å¼ºLLMç®¡ç†å™¨å¤±è´¥: {e}")
                # ç»§ç»­å°è¯•ä¼ ç»Ÿæ–¹æ³•
            
            # é™çº§ï¼šå°è¯•ä¼ ç»Ÿç»“æ„åŒ–è¾“å‡º
            try:
                self.logger.info("ğŸ”„ é™çº§åˆ°ä¼ ç»Ÿç»“æ„åŒ–è¾“å‡º...")
                # ä»promptä¸­åˆ†ç¦»ç³»ç»Ÿæç¤ºè¯å’Œç”¨æˆ·æç¤ºè¯
                system_prompt, user_prompt = self._split_prompt(prompt)
                
                structured_output = await self.llm_manager.generate_structured_output(
                    task_type='scene_splitting',
                    system_prompt=system_prompt,
                    user_prompt=user_prompt,
                    max_retries=2
                )
                
                if hasattr(structured_output, 'scenes') and structured_output.scenes:
                    # è½¬æ¢ä¸ºåŸæœ‰çš„Sceneå¯¹è±¡æ ¼å¼
                    scenes = []
                    for scene_data in structured_output.scenes:
                        scene = Scene(
                            sequence=scene_data.sequence,
                            content=scene_data.content,
                            image_prompt="",  # åç»­ç”Ÿæˆ
                            video_prompt="", # åç»­ç”Ÿæˆ
                            duration_seconds=getattr(scene_data, 'duration', 3.0),
                            animation_type="center_zoom_in",
                            subtitle_text=scene_data.content
                        )
                        scenes.append(scene)
                    
                    self.logger.info(f"âœ… ä¼ ç»Ÿç»“æ„åŒ–è¾“å‡ºæˆåŠŸ: {len(scenes)} scenes")
                    return scenes
                else:
                    # é™çº§åˆ°æ–‡æœ¬è§£æ
                    content = str(structured_output)
                    
            except Exception as e:
                self.logger.warning(f"ğŸ”„ ä¼ ç»Ÿç»“æ„åŒ–è¾“å‡ºå¤±è´¥ï¼Œé™çº§åˆ°æ–‡æœ¬è§£æ: {e}")
                
                # æœ€ç»ˆé™çº§ï¼šä¼ ç»Ÿæ–‡æœ¬ç”Ÿæˆ
                content = await self.llm_manager.call_llm_with_fallback(
                    prompt=prompt,
                    task_type='scene_splitting',
                    temperature=self.llm_config.temperature,
                    max_tokens=self.llm_config.max_tokens
                )
            
            if not content:
                raise ValueError("Empty response from all LLM providers")
            
            return content.strip()
            
        except Exception as e:
            self.logger.error(f"LLM API call failed: {e}")
            raise
    
    def _parse_scenes_response(self, response: str, request: SceneSplitRequest) -> List[Scene]:
        """
        è§£æåœºæ™¯åˆ†å‰²å“åº”
        
        Args:
            response: LLMå“åº”
            request: åŸå§‹è¯·æ±‚
        
        Returns:
            List[Scene]: è§£æçš„åœºæ™¯åˆ—è¡¨
        """
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_content = self._extract_json_from_response(response)
            
            if not json_content:
                self.logger.error(f"Failed to extract JSON from response. Response length: {len(response)}")
                self.logger.error(f"Response preview (first 1000 chars): {response[:1000]}")
                raise ValueError("No valid JSON found in response")
            
            self.logger.debug(f"Extracted JSON content: {json_content[:200]}...")
            
            try:
                data = json.loads(json_content)
            except json.JSONDecodeError as e:
                self.logger.error(f"JSON decode error: {e}")
                self.logger.error(f"Invalid JSON content: {json_content}")
                raise ValueError(f"Invalid JSON format: {e}")
            
            if 'scenes' not in data:
                raise ValueError("Missing 'scenes' key in response")
            
            scenes = []
            
            for i, scene_data in enumerate(data['scenes']):
                scene = Scene(
                    sequence=scene_data.get('sequence', i + 1),
                    content=scene_data.get('content', ''),
                    image_prompt=scene_data.get('image_prompt', ''),
                    video_prompt=scene_data.get('video_prompt', ''),  # æ–°å¢è§†é¢‘æç¤ºè¯å­—æ®µ
                    duration_seconds=scene_data.get('duration_seconds', request.scene_duration),
                    animation_type=scene_data.get('animation_type', 'è½»å¾®æ”¾å¤§'),
                    subtitle_text=scene_data.get('subtitle_text', scene_data.get('content', ''))
                )
                
                # éªŒè¯åœºæ™¯å†…å®¹
                if not scene.content:
                    raise ValueError(f"Empty content for scene {i + 1}")
                
                scenes.append(scene)
            
            if not scenes:
                raise ValueError("No scenes parsed from response")
            
            return scenes
            
        except json.JSONDecodeError as e:
            self.logger.error(f"JSON parsing error: {e}")
            self.logger.error(f"Raw LLM response that caused JSON error: {response[:1000]}...")
            raise ValueError(f"LLM returned invalid JSON format: {e}")
        except Exception as e:
            self.logger.error(f"Scene parsing error: {e}")
            self.logger.error(f"Raw LLM response: {response[:1000]}...")
            raise
    
    def _extract_json_from_response(self, response: str) -> Optional[str]:
        """ä»å“åº”ä¸­æå–JSONå†…å®¹"""
        import re
        
        self.logger.debug(f"Extracting JSON from response (length: {len(response)})")
        
        # æ–¹æ³•1: æŸ¥æ‰¾```json...```æ ¼å¼
        json_match = re.search(r'```json\s*\n?(.*?)\n?```', response, re.DOTALL | re.IGNORECASE)
        if json_match:
            content = json_match.group(1).strip()
            self.logger.debug("Found JSON in ```json``` block")
            return content
        
        # æ–¹æ³•2: æŸ¥æ‰¾```...```æ ¼å¼ï¼ˆå¯èƒ½æ²¡æœ‰æ ‡æ˜jsonï¼‰
        code_match = re.search(r'```\s*\n?(.*?)\n?```', response, re.DOTALL)
        if code_match:
            content = code_match.group(1).strip()
            if content.startswith('{') and content.endswith('}'):
                self.logger.debug("Found JSON in ``` block")
                return content
        
        # æ–¹æ³•3: æŸ¥æ‰¾åŒ…å«"scenes"çš„JSONå¯¹è±¡ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼‰
        json_obj_match = re.search(r'(\{.*?"scenes".*?\[.*?\].*?\})', response, re.DOTALL)
        if json_obj_match:
            content = json_obj_match.group(1)
            self.logger.debug("Found JSON with scenes key")
            return content
        
        # æ–¹æ³•4: å¯»æ‰¾å®Œæ•´çš„JSONå¤§æ‹¬å·åŒ¹é…
        start_pos = response.find('{')
        if start_pos != -1:
            bracket_count = 0
            for i, char in enumerate(response[start_pos:], start_pos):
                if char == '{':
                    bracket_count += 1
                elif char == '}':
                    bracket_count -= 1
                    if bracket_count == 0:
                        candidate = response[start_pos:i+1]
                        # éªŒè¯è¿™ç¡®å®åŒ…å«scenes
                        if '"scenes"' in candidate:
                            self.logger.debug("Found JSON through bracket matching")
                            return candidate
        
        # æ–¹æ³•5: å°è¯•å¤šä¸ªJSONå¯¹è±¡çš„æƒ…å†µ
        json_objects = re.findall(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', response, re.DOTALL)
        for obj in json_objects:
            if '"scenes"' in obj:
                self.logger.debug("Found JSON in multiple objects search")
                return obj
        
        # è®°å½•å“åº”å†…å®¹çš„å‰500å­—ç¬¦ç”¨äºè°ƒè¯•
        self.logger.warning(f"No JSON found in response. Response preview: {response[:500]}")
        return None
    
    # FALLBACK LOGIC REMOVED - ä¸å†ä½¿ç”¨é€€åŒ–é€»è¾‘æ©ç›–é—®é¢˜
    # def _fallback_scene_parsing(self, response: str, request: SceneSplitRequest) -> List[Scene]:
        """
        é€€åŒ–çš„åœºæ™¯è§£æï¼ˆå½“JSONè§£æå¤±è´¥æ—¶ï¼‰
        
        Args:
#             response: LLMå“åº”
#             request: åŸå§‹è¯·æ±‚
#         
#         Returns:
#             List[Scene]: è§£æçš„åœºæ™¯åˆ—è¡¨
#         """
#         self.logger.warning("Using fallback scene parsing")
#         
#         # ç®€å•åœ°å°†æ–‡æ¡ˆæŒ‰å¥å·åˆ†å‰²
#         sentences = [s.strip() for s in request.script_content.split('ã€‚') if s.strip()]
#         
#         # å¦‚æœå¥å­æ•°é‡ä¸å¤Ÿï¼ŒæŒ‰ç…§ç›®æ ‡æ•°é‡è¿›è¡Œå‡åŒ€åˆ†å‰²
#         if len(sentences) < request.target_scene_count:
#             # æŒ‰å­—ç¬¦æ•°åˆ†å‰²
#             content_length = len(request.script_content)
#             segment_length = content_length // request.target_scene_count
#             
#             scenes = []
#             for i in range(request.target_scene_count):
#                 start_idx = i * segment_length
#                 end_idx = (i + 1) * segment_length if i < request.target_scene_count - 1 else content_length
#                 
#                 segment = request.script_content[start_idx:end_idx].strip()
#                 
#                 scene = Scene(
#                     sequence=i + 1,
#                     content=segment,
#                     image_prompt=self._generate_fallback_image_prompt(segment, i + 1),
#                     duration_seconds=request.scene_duration,
#                     animation_type="è½»å¾®æ”¾å¤§",
#                     subtitle_text=segment[:50] + "..." if len(segment) > 50 else segment
#                 )
#                 
#                 scenes.append(scene)
#         else:
#             # å¦‚æœå¥å­å¤ªå¤šï¼Œåˆå¹¶ä¸€äº›å¥å­
#             scenes_per_sentence = len(sentences) // request.target_scene_count
#             scenes = []
#             
#             for i in range(request.target_scene_count):
#                 start_idx = i * scenes_per_sentence
#                 end_idx = (i + 1) * scenes_per_sentence if i < request.target_scene_count - 1 else len(sentences)
#                 
#                 content = 'ã€‚'.join(sentences[start_idx:end_idx]) + 'ã€‚'
#                 
#                 scene = Scene(
#                     sequence=i + 1,
#                     content=content,
#                     image_prompt=self._generate_fallback_image_prompt(content, i + 1),
#                     duration_seconds=request.scene_duration,
#                     animation_type="è½»å¾®æ”¾å¤§",
#                     subtitle_text=content[:50] + "..." if len(content) > 50 else content
#                 )
#                 
#                 scenes.append(scene)
#         
#         return scenes
# 
#     def _ensure_valid_image_prompts(self, scenes: List[Scene], request: SceneSplitRequest) -> List[Scene]:
#         """æ ¡éªŒå¹¶ä¿®æ­£åœºæ™¯çš„å›¾åƒæç¤ºè¯ï¼Œç¡®ä¿è‹±æ–‡ã€å¤šæ ·ä¸”ä¸è¿‡åº¦é‡å¤"""
#         def contains_non_ascii(s: str) -> bool:
#             try:
#                 s.encode('ascii')
#                 return False
#             except Exception:
#                 return True
#         
#         seen_prompts = set()
#         fixed_scenes: List[Scene] = []
#         for idx, scene in enumerate(scenes, start=1):
#             prompt = scene.image_prompt or ""
#             needs_fix = False
#             if not prompt:
#                 needs_fix = True
#             elif contains_non_ascii(prompt):
#                 needs_fix = True
#             elif len(prompt) < 30:
#                 needs_fix = True
#             elif prompt in seen_prompts:
#                 needs_fix = True
#             
#             if needs_fix:
#                 new_prompt = self._generate_fallback_image_prompt(scene.content, idx)
#                 self.logger.debug(f"Fixing image_prompt for scene {idx}: '{prompt[:40]}' -> '{new_prompt[:60]}'")
#                 prompt = new_prompt
#             
#             seen_prompts.add(prompt)
#             fixed_scenes.append(Scene(
#                 sequence=scene.sequence,
#                 content=scene.content,
#                 image_prompt=prompt,
#                 duration_seconds=scene.duration_seconds,
#                 animation_type=scene.animation_type,
#                 subtitle_text=scene.subtitle_text
#             ))
#         return fixed_scenes
#     
#     def _split_by_coze_rules(self, request: SceneSplitRequest, tts_subtitles: Optional[List] = None) -> List[Scene]:
#         """
#         æŒ‰ç…§åŸCozeå·¥ä½œæµè§„åˆ™åˆ†å‰²åœºæ™¯ï¼šç¬¬ä¸€å¥å•ç‹¬æˆæ®µï¼Œåç»­æ¯2å¥ä¸€æ®µ
#         
#         Args:
#             request: åœºæ™¯åˆ†å‰²è¯·æ±‚
#             tts_subtitles: TTSè¿”å›çš„å­—å¹•æ—¶é—´æˆ³ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
#         
#         Returns:
#             List[Scene]: åœºæ™¯åˆ—è¡¨
#         """
#         # æŒ‰å¥å·åˆ†å‰²å¥å­ï¼Œä¿ç•™å¥å·
#         sentences = []
#         current_sentence = ""
#         
#         for char in request.script_content:
#             current_sentence += char
#             if char in ['ã€‚', 'ï¼', 'ï¼Ÿ']:  # ä¸­æ–‡å¥æœ«æ ‡ç‚¹(æ¢å¤åŸé€»è¾‘)
#                 if current_sentence.strip():
#                     sentences.append(current_sentence.strip())
#                 current_sentence = ""
#         
#         # å¦‚æœæœ€åæ²¡æœ‰å¥æœ«æ ‡ç‚¹ï¼Œæ·»åŠ æœ€åä¸€æ®µ
#         if current_sentence.strip():
#             sentences.append(current_sentence.strip())
#         
#         if not sentences:
#             # å¦‚æœæ²¡æœ‰å¥å­ï¼Œå°†æ•´ä¸ªæ–‡æœ¬ä½œä¸ºä¸€ä¸ªåœºæ™¯
#             scenes = [Scene(
#                 sequence=1,
#                 content=request.script_content,
#                 image_prompt=self._generate_fallback_image_prompt(request.script_content, 1),
#                 duration_seconds=request.scene_duration,
#                 animation_type="è½»å¾®æ”¾å¤§",
#                 subtitle_text=request.script_content[:50] + "..." if len(request.script_content) > 50 else request.script_content
#             )]
#             return scenes
#         
#         scenes = []
#         
#         # ç¬¬ä¸€å¥å•ç‹¬æˆæ®µ
#         if sentences:
#             first_sentence = sentences[0]
#             # è®¡ç®—ç¬¬ä¸€å¥çš„æ—¶é•¿
#             duration = self._calculate_scene_duration(first_sentence, 0, 1, tts_subtitles) if tts_subtitles else request.scene_duration
#             
#             scene = Scene(
#                 sequence=1,
#                 content=first_sentence,
#                 image_prompt=self._generate_fallback_image_prompt(first_sentence, 1),
#                 duration_seconds=duration,
#                 animation_type="è½»å¾®æ”¾å¤§",
#                 subtitle_text=first_sentence
#             )
#             scenes.append(scene)
#         
#         # åç»­æ¯2å¥ä¸€æ®µ - æ·»åŠ é•¿åº¦é¢„æ£€æŸ¥
#         remaining_sentences = sentences[1:]
#         scene_num = 2
#         sentence_index = 1  # ä»ç¬¬äºŒå¥å¼€å§‹è®¡æ•°
#         
#         for i in range(0, len(remaining_sentences), 2):
#             # å–æœ€å¤š2å¥ï¼Œä½†è¦æ£€æŸ¥é•¿åº¦é™åˆ¶
#             scene_sentences = remaining_sentences[i:i+2]
#             scene_content = ''.join(scene_sentences)
#             
#             # ğŸ” é•¿åº¦é¢„æ£€æŸ¥: å¦‚æœåœºæ™¯å†…å®¹è¿‡é•¿(>30å­—ç¬¦)ï¼Œå•å¥æˆæ®µ  
#             if len(scene_content) > 30 and len(scene_sentences) > 1:
#                 # ç¬¬ä¸€å¥å•ç‹¬æˆæ®µ
#                 first_content = scene_sentences[0]
#                 duration1 = self._calculate_scene_duration(first_content, sentence_index, 1, tts_subtitles) if tts_subtitles else request.scene_duration
#                 
#                 scene1 = Scene(
#                     sequence=scene_num,
#                     content=first_content,
#                     image_prompt=self._generate_fallback_image_prompt(first_content, scene_num),
#                     duration_seconds=duration1,
#                     animation_type="è½»å¾®æ”¾å¤§",
#                     subtitle_text=first_content
#                 )
#                 scenes.append(scene1)
#                 scene_num += 1
#                 
#                 # å¦‚æœæœ‰ç¬¬äºŒå¥ï¼Œä¹Ÿå•ç‹¬æˆæ®µ
#                 if len(scene_sentences) > 1:
#                     second_content = scene_sentences[1]
#                     duration2 = self._calculate_scene_duration(second_content, sentence_index + 1, 1, tts_subtitles) if tts_subtitles else request.scene_duration
#                     
#                     scene2 = Scene(
#                         sequence=scene_num,
#                         content=second_content,
#                         image_prompt=self._generate_fallback_image_prompt(second_content, scene_num),
#                         duration_seconds=duration2,
#                         animation_type="è½»å¾®æ”¾å¤§",
#                         subtitle_text=second_content
#                     )
#                     scenes.append(scene2)
#                     scene_num += 1
#             else:
#                 # é•¿åº¦åˆé€‚ï¼ŒæŒ‰åŸé€»è¾‘å¤„ç†
#                 sentences_in_scene = len(scene_sentences)
#                 duration = self._calculate_scene_duration(scene_content, sentence_index, sentences_in_scene, tts_subtitles) if tts_subtitles else request.scene_duration
#                 
#                 scene = Scene(
#                     sequence=scene_num,
#                     content=scene_content,
#                     image_prompt=self._generate_fallback_image_prompt(scene_content, scene_num),
#                     duration_seconds=duration,
#                     animation_type="è½»å¾®æ”¾å¤§",
#                     subtitle_text=scene_content
#                 )
#                 scenes.append(scene)
#                 scene_num += 1
#             
#             sentence_index += len(scene_sentences)
#         
#         self.logger.info(f"Coze rules splitting: {len(sentences)} sentences â†’ {len(scenes)} scenes")
#         self.logger.debug(f"Scene breakdown: Scene 1 (1 sentence), Scenes 2-{len(scenes)} ({len(remaining_sentences)} sentences in groups of 2)")
#         
#         return scenes
#     
#     def _calculate_scene_duration(self, scene_content: str, sentence_start_index: int, sentences_count: int, tts_subtitles: Optional[List]) -> float:
#         """
#         åŸºäºTTSå­—å¹•ä¿¡æ¯è®¡ç®—åœºæ™¯æ—¶é•¿
#         
#         Args:
#             scene_content: åœºæ™¯å†…å®¹
#             sentence_start_index: å¥å­èµ·å§‹ç´¢å¼•
#             sentences_count: å¥å­æ•°é‡
#             tts_subtitles: TTSå­—å¹•åˆ—è¡¨
#         
#         Returns:
#             float: åœºæ™¯æ—¶é•¿ï¼ˆç§’ï¼‰
#         """
#         if not tts_subtitles:
#             # æ ¹æ®å­—ç¬¦æ•°é‡ä¼°ç®—æ—¶é•¿ï¼ˆæ¯åˆ†é’Ÿçº¦300å­—ï¼‰
#             chars_per_minute = 300
#             estimated_duration = (len(scene_content) / chars_per_minute) * 60
#             return max(2.0, min(estimated_duration, 10.0))  # é™åˆ¶åœ¨2-10ç§’ä¹‹é—´
#         
#         try:
#             # å°è¯•æ ¹æ®TTSå­—å¹•è®¡ç®—ç²¾ç¡®æ—¶é•¿
#             # æ‰¾åˆ°åœºæ™¯å†…å®¹å¯¹åº”çš„å­—å¹•æ®µ
#             scene_start_time = None
#             scene_end_time = None
#             
#             for subtitle in tts_subtitles:
#                 subtitle_text = subtitle.get('text', '').strip()
#                 if not subtitle_text:
#                     continue
#                     
#                 # æ£€æŸ¥æ˜¯å¦åŒ…å«åœºæ™¯çš„å¼€å§‹æ–‡æœ¬
#                 if scene_start_time is None and scene_content[:20] in subtitle_text:
#                     scene_start_time = subtitle.get('start', 0)
#                 
#                 # æ£€æŸ¥æ˜¯å¦åŒ…å«åœºæ™¯çš„ç»“æŸæ–‡æœ¬
#                 if scene_content[-20:] in subtitle_text:
#                     scene_end_time = subtitle.get('end', subtitle.get('start', 0))
#             
#             if scene_start_time is not None and scene_end_time is not None:
#                 duration = scene_end_time - scene_start_time
#                 if duration > 0:
#                     self.logger.debug(f"TTS-based duration for scene: {duration:.2f}s")
#                     return duration
#         
#         except Exception as e:
#             self.logger.warning(f"Failed to calculate TTS-based duration: {e}")
#         
#         # é€€åŒ–æ–¹æ¡ˆï¼šåŸºäºå­—ç¬¦æ•°é‡ä¼°ç®—
#         chars_per_minute = 300
#         estimated_duration = (len(scene_content) / chars_per_minute) * 60
#         return max(2.0, min(estimated_duration, 10.0))  # é™åˆ¶åœ¨2-10ç§’ä¹‹é—´
# 
#     # FALLBACK LOGIC REMOVED - ä¸å†ä½¿ç”¨é€€åŒ–é€»è¾‘æ©ç›–é—®é¢˜  
#     # def _generate_fallback_image_prompt(self, content: str, sequence: int) -> str:
#         """
#         ç”Ÿæˆé€€åŒ–å›¾åƒæç¤ºè¯ï¼ˆåŸºäºå†…å®¹è€Œéå ä½ç¬¦ï¼‰
#         
#         Args:
#             content: åœºæ™¯å†…å®¹
#             sequence: åœºæ™¯åºå·
#         
#         Returns:
#             str: å›¾åƒæç¤ºè¯
#         """
#         import re
#         
#         # æå–å…³é”®è¯æ¥ç”Ÿæˆå›¾åƒæè¿°
#         keywords = {
#             'characters': [],
#             'places': [],
#             'actions': [],
#             'objects': []
#         }
#         
#         # å¸¸è§å†å²äººç‰©åç§°
#         historical_figures = ['ç§¦å§‹çš‡', 'å¬´æ”¿', 'æœ±å…ƒç’‹', 'æ±‰æ­¦å¸', 'å”å¤ªå®—', 'åº·ç†™', 'ä¹¾éš†', 'æ­¦åˆ™å¤©', 'æä¸–æ°‘', 'åˆ˜é‚¦', 'é¡¹ç¾½']
#         for figure in historical_figures:
#             if figure in content:
#                 keywords['characters'].append(figure)
#         
#         # å¸¸è§åœ°ç‚¹
#         places = ['å’¸é˜³', 'é•¿å®‰', 'åŒ—äº¬', 'å—äº¬', 'æ´›é˜³', 'æ±´æ¢', 'å®«æ®¿', 'çš‡å®«', 'åŸå¢™', 'æˆ˜åœº', 'æœå ‚']
#         for place in places:
#             if place in content:
#                 keywords['places'].append(place)
#         
#         # åŠ¨ä½œè¯
#         actions = ['æˆ˜æ–—', 'å¾æˆ˜', 'ç»Ÿä¸€', 'å»ºç«‹', 'æ¨ç¿»', 'ç§°å¸', 'ç™»åŸº', 'æ²»ç†', 'æ”¹é©', 'å˜æ³•']
#         for action in actions:
#             if action in content:
#                 keywords['actions'].append(action)
#         
#         # ç‰©å“
#         objects = ['é¾™è¢', 'é“ ç”²', 'å…µå™¨', 'åŸæ± ', 'å†›é˜Ÿ', 'æ——å¸œ', 'å®«æ®¿', 'å»ºç­‘']
#         for obj in objects:
#             if obj in content:
#                 keywords['objects'].append(obj)
#         
#         # åˆ›å»ºä¸­æ–‡åˆ°è‹±æ–‡çš„äººç‰©æ˜ å°„
#         character_mapping = {
#             'ç§¦å§‹çš‡': 'Emperor Qin Shi Huang',
#             'å¬´æ”¿': 'Emperor Qin Shi Huang',
#             'æœ±å…ƒç’‹': 'Emperor Zhu Yuanzhang',
#             'æ±‰æ­¦å¸': 'Emperor Wu of Han',
#             'å”å¤ªå®—': 'Emperor Taizong of Tang',
#             'åº·ç†™': 'Emperor Kangxi',
#             'ä¹¾éš†': 'Emperor Qianlong',
#             'æ­¦åˆ™å¤©': 'Empress Wu Zetian',
#             'æä¸–æ°‘': 'Emperor Taizong Li Shimin',
#             'åˆ˜é‚¦': 'Emperor Liu Bang',
#             'é¡¹ç¾½': 'Xiang Yu'
#         }
#         
#         # åˆ›å»ºä¸­æ–‡åˆ°è‹±æ–‡çš„åœ°ç‚¹æ˜ å°„
#         place_mapping = {
#             'å’¸é˜³': 'Xianyang',
#             'é•¿å®‰': "Chang'an",
#             'åŒ—äº¬': 'Beijing',
#             'å—äº¬': 'Nanjing',
#             'æ´›é˜³': 'Luoyang',
#             'æ±´æ¢': 'Bianliang',
#             'å®«æ®¿': 'imperial palace',
#             'çš‡å®«': 'royal palace',
#             'åŸå¢™': 'city walls',
#             'æˆ˜åœº': 'battlefield',
#             'æœå ‚': 'imperial court'
#         }
#         
#         # æ ¹æ®å…³é”®è¯ç»„åˆç”Ÿæˆè‹±æ–‡æè¿°ï¼Œå¹¶å¼•å…¥ä¸åŒé•œå¤´ä¸è§†è§’ï¼Œé¿å…é‡å¤
#         camera_angles = [
#             'close-up portrait',
#             'wide establishing shot',
#             'low-angle dramatic shot',
#             'bird\'s-eye view',
#             'over-the-shoulder view',
#             'three-quarter view',
#             'side profile shot',
#             'back view silhouette'
#         ]
#         # äº¤æ›¿ä½¿ç”¨è§’åº¦
#         angle = camera_angles[(sequence - 1) % len(camera_angles)]
#         if keywords['characters']:
#             character_cn = keywords['characters'][0]
#             character_en = character_mapping.get(character_cn, 'ancient Chinese emperor')
#             if keywords['places']:
#                 place_cn = keywords['places'][0]
#                 place_en = place_mapping.get(place_cn, 'ancient Chinese location')
#                 return f"Ancient China, {character_en} in {place_en}, {angle}, wearing traditional imperial robes, stern and majestic expression, historical realistic style, ancient horror atmosphere, white background, dim colors, traditional clothing, high definition, high contrast, low saturation colors"
#             else:
#                 return f"Ancient China, {character_en}, {angle}, wearing black dragon robe, stern and majestic face, ancient imperial palace background, historical realistic style, ancient horror atmosphere, white background, traditional clothing, high definition, high contrast, low saturation colors"
#         elif keywords['places']:
#             place_cn = keywords['places'][0]
#             place_en = place_mapping.get(place_cn, 'ancient Chinese architecture')
#             return f"Ancient China {place_en}, {angle}, magnificent architecture, ancient architectural style, dim lighting, rich historical atmosphere, ancient horror style, white background, traditional elements, high definition, high contrast, low saturation colors, solemn atmosphere"
#         elif keywords['actions']:
#             return f"Ancient China historical scene, {angle}, traditional costumes, ancient architectural background, historical realistic style, ancient horror atmosphere, white background, dim colors, traditional clothing, high definition, high contrast, low saturation colors, solemn atmosphere"
#         else:
#             # æœ€åçš„é€šç”¨è‹±æ–‡æè¿°
#             return f"Ancient China historical scene, {angle}, traditional clothing, ancient architecture, dim tones, historical realistic style, ancient horror atmosphere, white background, traditional elements, high definition, high contrast, low saturation colors, solemn atmosphere"
#     
    def _scene_to_dict(self, scene: Scene) -> Dict[str, Any]:
        """å°†Sceneå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'sequence': scene.sequence,
            'content': scene.content,
            'image_prompt': scene.image_prompt,
            'video_prompt': scene.video_prompt,  # æ·»åŠ è§†é¢‘æç¤ºè¯å­—æ®µ
            'duration_seconds': scene.duration_seconds,
            'animation_type': scene.animation_type,
            'subtitle_text': scene.subtitle_text
        }
    

    
    def split_scenes_sync(self, request: SceneSplitRequest) -> SceneSplitResult:
        """
        åŒæ­¥åˆ†å‰²åœºæ™¯ï¼ˆå¯¹å¼‚æ­¥æ–¹æ³•çš„åŒ…è£…ï¼‰
        
        Args:
            request: åœºæ™¯åˆ†å‰²è¯·æ±‚
        
        Returns:
            SceneSplitResult: åˆ†å‰²ç»“æœ
        """
        return asyncio.run(self.split_scenes_async(request))
    
    async def batch_split_scenes(self, requests: List[SceneSplitRequest], 
                               max_concurrent: int = 2) -> List[SceneSplitResult]:
        """
        æ‰¹é‡åœºæ™¯åˆ†å‰²
        
        Args:
            requests: åˆ†å‰²è¯·æ±‚åˆ—è¡¨
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
        
        Returns:
            List[SceneSplitResult]: åˆ†å‰²ç»“æœåˆ—è¡¨
        """
        self.logger.info(f"Starting batch scene splitting: {len(requests)} requests")
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def split_with_semaphore(request: SceneSplitRequest) -> SceneSplitResult:
            async with semaphore:
                return await self.split_scenes_async(request)
        
        # æ‰§è¡Œå¹¶å‘åˆ†å‰²
        tasks = [split_with_semaphore(request) for request in requests]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœå’Œå¼‚å¸¸
        successful_results = []
        failed_count = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                self.logger.error(f"Batch scene splitting failed for request {i}: {result}")
                failed_count += 1
            else:
                successful_results.append(result)
        
        self.logger.info(f"Batch scene splitting completed: {len(successful_results)} successful, {failed_count} failed")
        
        return successful_results
    
    def save_scenes(self, result: SceneSplitResult, output_dir: Optional[str] = None) -> str:
        """
        ä¿å­˜åœºæ™¯åˆ†å‰²ç»“æœåˆ°æ–‡ä»¶
        
        Args:
            result: åœºæ™¯åˆ†å‰²ç»“æœ
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if not output_dir:
            filename = self.file_manager.generate_filename(
                content=result.original_script,
                prefix=f"scenes_{result.language}",
                extension="json"
            )
            filepath = self.file_manager.get_output_path('scenes', filename)
        else:
            filepath = Path(output_dir) / f"scenes_{result.language}_{int(time.time())}.json"
        
        # å‡†å¤‡ä¿å­˜æ•°æ®
        save_data = {
            'metadata': {
                'language': result.language,
                'total_duration': result.total_duration,
                'scene_count': len(result.scenes),
                'model_used': result.model_used,
                'split_time': result.split_time,
                'created_at': time.strftime('%Y-%m-%d %H:%M:%S')
            },
            'original_script': result.original_script,
            'scenes': [self._scene_to_dict(scene) for scene in result.scenes]
        }
        
        success = self.file_manager.save_json(save_data, filepath)
        
        if success:
            self.logger.info(f"Saved scenes to: {filepath}")
            return str(filepath)
        else:
            raise Exception(f"Failed to save scenes to: {filepath}")
    
    def update_scene_durations_with_tts(self, scenes: List[Scene], tts_subtitles: List) -> List[Scene]:
        """
        ä½¿ç”¨TTSå­—å¹•ä¿¡æ¯æ›´æ–°åœºæ™¯æ—¶é•¿
        
        Args:
            scenes: åŸå§‹åœºæ™¯åˆ—è¡¨
            tts_subtitles: TTSå­—å¹•ä¿¡æ¯
        
        Returns:
            List[Scene]: æ›´æ–°æ—¶é•¿åçš„åœºæ™¯åˆ—è¡¨
        """
        updated_scenes = []
        
        for scene in scenes:
            # é‡æ–°è®¡ç®—æ—¶é•¿
            new_duration = self._calculate_scene_duration(scene.content, scene.sequence - 1, 1, tts_subtitles)
            
            # åˆ›å»ºæ–°çš„åœºæ™¯å¯¹è±¡
            updated_scene = Scene(
                sequence=scene.sequence,
                content=scene.content,
                image_prompt=scene.image_prompt,
                duration_seconds=new_duration,
                animation_type=scene.animation_type,
                subtitle_text=scene.subtitle_text
            )
            updated_scenes.append(updated_scene)
            
            self.logger.debug(f"Scene {scene.sequence} duration updated: {scene.duration_seconds:.2f}s â†’ {new_duration:.2f}s")
        
        total_duration = sum(scene.duration_seconds for scene in updated_scenes)
        self.logger.info(f"Updated scene durations with TTS data: total {total_duration:.2f}s")
        
        return updated_scenes

    def get_splitting_stats(self) -> Dict[str, Any]:
        """è·å–åˆ†å‰²ç»Ÿè®¡ä¿¡æ¯"""
        
        return {
            'supported_languages': self.supported_languages,
            'model_config': {
                'name': self.llm_config.name,
                'temperature': self.llm_config.temperature,
                'max_tokens': self.llm_config.max_tokens
            }
        }
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"SceneSplitter(model={self.llm_config.name}, languages={self.supported_languages})"