"""
éŸ³é¢‘ç”Ÿæˆå™¨ - å¤šæä¾›å•†è¯­éŸ³åˆæˆæ”¯æŒ
æ”¯æŒAzure TTSã€ElevenLabsã€OpenAI TTSç­‰æä¾›å•†
"""
import asyncio
import aiohttp
import base64
import time
import json
import os
import subprocess
from typing import Dict, List, Optional, Any, Union
from pathlib import Path
import logging
from dataclasses import dataclass
import hashlib
from io import BytesIO

from core.config_manager import ConfigManager
from utils.file_manager import FileManager

# ElevenLabs imports (éœ€è¦å…ˆå®‰è£…: pip install elevenlabs)
try:
    from elevenlabs.client import ElevenLabs
    ELEVENLABS_AVAILABLE = True
except ImportError:
    ELEVENLABS_AVAILABLE = False

@dataclass
class AudioGenerationRequest:
    """éŸ³é¢‘ç”Ÿæˆè¯·æ±‚"""
    text: str                     # è¦åˆæˆçš„æ–‡æœ¬
    language: str                 # è¯­è¨€ä»£ç 
    voice_id: str = ""           # éŸ³è‰²ID
    voice_style: str = ""        # è¯­éŸ³é£æ ¼
    speed: float = 1.2           # è¯­é€Ÿï¼ˆå¯¹åº”åŸå·¥ä½œæµï¼‰
    volume: float = 1.0          # éŸ³é‡
    format: str = "mp3"          # è¾“å‡ºæ ¼å¼

@dataclass  
class AudioSubtitle:
    """éŸ³é¢‘å­—å¹•ä¿¡æ¯"""
    text: str                    # å­—å¹•æ–‡æœ¬
    start_time: float           # å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
    end_time: float             # ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    duration: float             # æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰

@dataclass
class GeneratedAudio:
    """ç”Ÿæˆçš„éŸ³é¢‘"""
    audio_data: bytes            # éŸ³é¢‘æ•°æ®
    text: str                    # åŸå§‹æ–‡æœ¬
    language: str                # è¯­è¨€
    voice_id: str                # ä½¿ç”¨çš„éŸ³è‰²
    duration_seconds: float      # éŸ³é¢‘æ—¶é•¿
    file_size: int               # æ–‡ä»¶å¤§å°
    provider: str                # æä¾›å•†
    format: str                  # éŸ³é¢‘æ ¼å¼
    generation_time: float       # ç”Ÿæˆè€—æ—¶
    file_path: Optional[str] = None  # ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    subtitles: Optional[List[AudioSubtitle]] = None  # å­—å¹•æ—¶é—´æˆ³ä¿¡æ¯

class AudioGenerator:
    """
    éŸ³é¢‘ç”Ÿæˆå™¨ - æ”¯æŒå¤šä¸ªæä¾›å•†
    
    æ”¯æŒçš„æä¾›å•†ï¼š
    1. Azure TTS - ä¸»è¦æä¾›å•†ï¼ˆå¯¹åº”åŸå·¥ä½œæµæ‚¬ç–‘è§£è¯´éŸ³è‰²ï¼‰
    2. ElevenLabs - å¤‡ç”¨ï¼ˆé«˜è´¨é‡è¯­éŸ³ï¼‰
    3. OpenAI TTS - å¤‡ç”¨
    """
    
    def __init__(self, config_manager: ConfigManager, 
                 file_manager: FileManager):
        self.config = config_manager
        self.file_manager = file_manager
        self.logger = logging.getLogger('story_generator.media')
        
        # è·å–éŸ³é¢‘é…ç½®
        self.audio_config = config_manager.get('media.audio', {})
        
        # APIå¯†é’¥
        self.api_keys = {
            'minimax': config_manager.get_api_key('minimax'),
            'elevenlabs': config_manager.get_api_key('elevenlabs'),
            'openai': config_manager.get_api_key('openrouter')
        }
        
        # æä¾›å•†ä¼˜å…ˆçº§ - æ”¯æŒæŒ‰è¯­è¨€é…ç½®
        primary_provider_config = self.audio_config.get('primary_provider', 'minimax')
        if isinstance(primary_provider_config, dict):
            # æŒ‰è¯­è¨€é…ç½®
            self.language_providers = primary_provider_config
            self.primary_provider = primary_provider_config.get('zh', 'minimax')  # é»˜è®¤ä½¿ç”¨ä¸­æ–‡é…ç½®
        else:
            # ç»Ÿä¸€é…ç½®
            self.primary_provider = primary_provider_config
            self.language_providers = {
                'zh': self.primary_provider,
                'en': self.primary_provider,
                'es': self.primary_provider,
            }
        
        # fallbackæœºåˆ¶å·²ç§»é™¤ï¼Œåªä½¿ç”¨ä¸»è¦æä¾›å•†
        
        # è¯­éŸ³é…ç½®
        self._load_voice_configs()
        
        # åˆå§‹åŒ–ElevenLabså®¢æˆ·ç«¯
        if ELEVENLABS_AVAILABLE and self.api_keys.get('elevenlabs'):
            self.elevenlabs_client = ElevenLabs(api_key=self.api_keys['elevenlabs'])
        else:
            self.elevenlabs_client = None
        
        self.logger.info(f"Audio generator initialized with primary provider: {self.primary_provider}")
    
    def _get_actual_audio_duration_from_data(self, audio_data: bytes) -> float:
        """ä»éŸ³é¢‘æ•°æ®è·å–å®é™…æ—¶é•¿"""
        try:
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            temp_path = self.file_manager.get_temp_path('audio', f'duration_check_{int(time.time())}.mp3')
            with open(temp_path, 'wb') as f:
                f.write(audio_data)
            
            # ä½¿ç”¨FFprobeè·å–æ—¶é•¿
            result = subprocess.run([
                'ffprobe', '-v', 'quiet',
                '-show_entries', 'format=duration',
                '-of', 'csv=p=0',
                temp_path
            ], capture_output=True, text=True)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_path)
            except:
                pass
            
            if result.returncode == 0 and result.stdout.strip():
                return float(result.stdout.strip())
            else:
                return 0.0
                
        except Exception as e:
            self.logger.warning(f"Failed to get audio duration from data: {e}")
            return 0.0
    
    def _load_voice_configs(self):
        """åŠ è½½è¯­éŸ³é…ç½®"""
        # è¯­éŸ³é…ç½®
        self.voice_configs = {
            'minimax': {
                'zh': {
                    'voice_id': 'male-qn-qingse',  # MiniMaxä¸­æ–‡ç”·å£°
                    'style': 'audiobook'
                },
                'en': {
                    'voice_id': 'male-qn-qingse',  # ä½¿ç”¨ä¸­æ–‡è¯­éŸ³ï¼ŒMiniMaxæ”¯æŒ
                    'style': 'audiobook'
                }
            },
            'azure': {
                'zh': {
                    'voice_id': 'zh-CN-XiaoxiaoNeural',  # ä¸­æ–‡æ‚¬ç–‘éŸ³è‰²
                    'style': 'newscast',
                    'role': 'narrator'
                },
                'en': {
                    'voice_id': 'en-US-AriaNeural',
                    'style': 'newscast',
                    'role': 'narrator'
                },
                'es': {
                    'voice_id': 'es-ES-ElviraNeural',
                    'style': 'newscast',
                    'role': 'narrator'
                }
            },
            'elevenlabs': {
                'zh': {'voice_id': 'pNInz6obpgDQGcFmaJgB'},  # ä¸­æ–‡éŸ³è‰²
                'en': {'voice_id': 'EXAVITQu4vr4xnSDxMaL'},  # è‹±æ–‡éŸ³è‰²
                'es': {'voice_id': 'XrExE9yKIg1WjnnlVkGX'}   # è¥¿ç­ç‰™è¯­éŸ³è‰²
            },
            'openai': {
                'voice_id': 'alloy'  # OpenAIç»Ÿä¸€ä½¿ç”¨alloyéŸ³è‰²
            }
        }
        
        # é»˜è®¤è¯­éŸ³IDï¼ˆå¯¹åº”åŸå·¥ä½œæµï¼‰
        self.default_voice_id = self.audio_config.get('voice_id', '7468512265134932019')
    
    async def generate_audio_async(self, request: AudioGenerationRequest, 
                                 provider: Optional[str] = None) -> GeneratedAudio:
        """
        å¼‚æ­¥ç”ŸæˆéŸ³é¢‘
        
        Args:
            request: éŸ³é¢‘ç”Ÿæˆè¯·æ±‚
            provider: æŒ‡å®šæä¾›å•†ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            GeneratedAudio: ç”Ÿæˆçš„éŸ³é¢‘
        """
        start_time = time.time()
        
        try:
            # ç¼“å­˜å·²ç¦ç”¨ - æ¯æ¬¡éƒ½ç”Ÿæˆæ–°éŸ³é¢‘
            
            # æ™ºèƒ½é€‰æ‹©æä¾›å•†ï¼šåŸºäºè¯­è¨€ä¸“ç”¨ç­–ç•¥
            if provider:
                providers_to_try = [provider]
            else:
                # æ ¹æ®è¯­è¨€é€‰æ‹©æœ€ä½³æä¾›å•†
                preferred_provider = self.language_providers.get(request.language, self.primary_provider)
                
                # ç¡®ä¿preferred_provideræ˜¯å­—ç¬¦ä¸²
                if isinstance(preferred_provider, dict):
                    preferred_provider = preferred_provider.get(request.language, 'elevenlabs')
                
                # åªä½¿ç”¨é¦–é€‰æä¾›å•†ï¼Œä¸å†ä½¿ç”¨fallback
                providers_to_try = [preferred_provider]
            
            last_error = None
            for provider_name in providers_to_try:
                if not self.api_keys.get(provider_name):
                    self.logger.warning(f"No API key for provider: {provider_name}")
                    continue
                
                try:
                    self.logger.info(f"Generating audio with {provider_name}: {request.text[:30]}...")
                    
                    # ä¸ºæ¯ä¸ªprovideråˆ›å»ºé€‚å½“çš„è¯·æ±‚å‰¯æœ¬
                    provider_request = AudioGenerationRequest(
                        text=request.text,
                        language=request.language,
                        voice_id="",  # å°†ç”±å…·ä½“provideræ–¹æ³•è®¾ç½®
                        voice_style=request.voice_style,
                        speed=request.speed,
                        volume=request.volume,
                        format=request.format
                    )
                    
                    if provider_name == 'minimax':
                        result = await self._generate_with_minimax_sync(provider_request)
                    elif provider_name == 'azure':
                        result = await self._generate_with_azure(provider_request)
                    elif provider_name == 'elevenlabs':
                        result = await self._generate_with_elevenlabs(provider_request)
                    elif provider_name == 'openai':
                        result = await self._generate_with_openai(provider_request)
                    else:
                        continue
                    
                    # ç¼“å­˜ç»“æœ
                    cache_data = {
                        'audio_data': result.audio_data,
                        'text': result.text,
                        'language': result.language,
                        'voice_id': result.voice_id,
                        'duration_seconds': result.duration_seconds,
                        'file_size': result.file_size,
                        'provider': result.provider,
                        'format': result.format
                    }
                    
                    # ç¼“å­˜å·²ç¦ç”¨
                    
                    # è®°å½•æ—¥å¿—
                    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                    file_path = self.save_audio(result)
                    result.file_path = file_path
                    
                    logger = self.config.get_logger('story_generator')
                    logger.info(f"Media generation - Type: audio, Provider: {provider_name}, "
                               f"Processing time: {result.generation_time:.2f}s, "
                               f"File size: {result.file_size} bytes")
                    
                    self.logger.info(f"Generated audio successfully with {provider_name}: {result.duration_seconds:.1f}s, {result.file_size / 1024:.1f}KB")
                    self.logger.info(f"Audio saved to: {file_path}")
                    
                    return result
                    
                except Exception as e:
                    self.logger.error(f"Failed to generate audio with {provider_name}: {e}")
                    last_error = e
                    continue
            
            # æ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥äº†
            raise Exception(f"All audio providers failed. Last error: {last_error}")
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"Audio generation failed after {processing_time:.2f}s: {e}")
            
            # è®°å½•é”™è¯¯æ—¥å¿—
            logger = self.config.get_logger('story_generator')
            logger.error(f"Media generation failed - Type: audio, Provider: unknown, "
                        f"Processing time: {processing_time:.2f}s")
            
            raise
    
    async def _generate_with_minimax_sync(self, request: AudioGenerationRequest) -> GeneratedAudio:
        """ä½¿ç”¨MiniMaxåŒæ­¥TTSç”ŸæˆéŸ³é¢‘"""
        start_time = time.time()
        
        # è·å–è¯­éŸ³é…ç½®
        voice_config = self.voice_configs['minimax'].get(request.language, self.voice_configs['minimax']['zh'])
        voice_id = request.voice_id or voice_config['voice_id']
        
        # è·å–GroupId
        group_id = os.getenv('MINIMAX_GROUP_ID')
        if not group_id:
            group_id = '1961322907531485224'  # é»˜è®¤å€¼
        
        # MiniMaxåŒæ­¥TTS API
        api_url = f"https://api.minimaxi.com/v1/t2a_v2?GroupId={group_id}"
        
        payload = {
            "model": "speech-2.5-hd-preview",
            "text": request.text,
            "stream": False,  # åŒæ­¥æ¨¡å¼
            "language_boost": "Chinese" if request.language == 'zh' else "auto",
            "output_format": "hex",  # è¿”å›hexç¼–ç 
            "subtitle_enable": True,  # å¯ç”¨å­—å¹•åŠŸèƒ½
            "voice_setting": {
                "voice_id": voice_id,
                "speed": request.speed,
                "vol": request.volume,
                "pitch": 0,
                "emotion": "happy"
            },
            "audio_setting": {
                "sample_rate": 32000,
                "bitrate": 128000,
                "format": "mp3",
                "channel": 1
            }
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_keys['minimax']}",
            "Content-Type": "application/json"
        }
        
        self.logger.info(f"Using MiniMax sync TTS with GroupId: {group_id}")
        
        # é‡è¯•æœºåˆ¶é…ç½®
        max_retries = self.config.get('general.api_max_retries', 3)
        retry_delay = self.config.get('general.retry_delay', 2)
        timeout_seconds = self.config.get('general.api_timeout', 180)  # å¢åŠ åˆ°3åˆ†é’Ÿ
        
        last_error = None
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    self.logger.info(f"ğŸ”„ MiniMax retry attempt {attempt + 1}/{max_retries} after {retry_delay}s...")
                    await asyncio.sleep(retry_delay)
                
                timeout_config = aiohttp.ClientTimeout(total=timeout_seconds)
                async with aiohttp.ClientSession(timeout=timeout_config) as session:
                    async with session.post(api_url, json=payload, headers=headers) as response:
                        if response.status != 200:
                            error_text = await response.text()
                            raise Exception(f"MiniMax sync API error {response.status}: {error_text}")
                        
                        result = await response.json()
                        break  # æˆåŠŸåè·³å‡ºé‡è¯•å¾ªç¯
                        
            except (asyncio.TimeoutError, aiohttp.ClientError, Exception) as e:
                last_error = e
                error_str = str(e).lower()
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
                should_retry = any(keyword in error_str for keyword in [
                    'timeout', 'connection', 'network', 'temporary', 'oss-cn', 'aliyuncs'
                ])
                
                if attempt < max_retries - 1 and should_retry:
                    self.logger.warning(f"â° MiniMax attempt {attempt + 1} failed: {e}")
                    continue
                else:
                    raise Exception(f"MiniMax sync failed after {max_retries} attempts: {e}")
        
        else:
            raise Exception(f"MiniMax sync failed after {max_retries} attempts: {last_error}")
        
        # å¤„ç†APIå“åº”
        self.logger.debug(f"MiniMax response keys: {list(result.keys())}")
        if 'data' in result:
            data_keys = list(result['data'].keys()) if result['data'] else []
            self.logger.debug(f"MiniMax data keys: {data_keys}")
        
        if result.get('base_resp', {}).get('status_code') != 0:
            error_msg = result.get('base_resp', {}).get('status_msg', 'Unknown error')
            raise Exception(f"MiniMax sync failed: {error_msg}")
        
        # è·å–hexç¼–ç çš„éŸ³é¢‘æ•°æ®
        hex_audio = result.get('data', {}).get('audio')
        if not hex_audio:
            raise Exception("No audio data in MiniMax response")
        
        # è§£ç hexæ•°æ®ä¸ºbytes
        audio_data = bytes.fromhex(hex_audio)
        
        self.logger.info(f"MiniMax sync TTS completed: {len(audio_data)} bytes")
        
        # å¤„ç†å­—å¹•æ•°æ®ï¼ˆMiniMaxè¿”å›å­—å¹•æ–‡ä»¶URLï¼‰
        subtitles = []
        subtitle_file_url = result.get('data', {}).get('subtitle_file')
        
        if subtitle_file_url:
            self.logger.info(f"Downloading subtitle file from MiniMax")
            self.logger.debug(f"Subtitle file URL: {subtitle_file_url}")
            
            # ä¸‹è½½å­—å¹•æ–‡ä»¶ï¼Œå¸¦é‡è¯•æœºåˆ¶
            subtitle_content = None
            for sub_attempt in range(max_retries):
                try:
                    if sub_attempt > 0:
                        self.logger.info(f"ğŸ”„ Subtitle download retry {sub_attempt + 1}/{max_retries}...")
                        await asyncio.sleep(retry_delay)
                    
                    timeout_config = aiohttp.ClientTimeout(total=timeout_seconds)
                    async with aiohttp.ClientSession(timeout=timeout_config) as subtitle_session:
                        async with subtitle_session.get(subtitle_file_url) as subtitle_response:
                            if subtitle_response.status == 200:
                                subtitle_content = await subtitle_response.text()
                                self.logger.debug(f"Subtitle file content preview: {subtitle_content[:200]}...")
                                break  # æˆåŠŸä¸‹è½½ï¼Œé€€å‡ºé‡è¯•å¾ªç¯
                            else:
                                raise Exception(f"Subtitle download failed with status {subtitle_response.status}")
                                
                except (asyncio.TimeoutError, aiohttp.ClientError, Exception) as e:
                    if sub_attempt < max_retries - 1:
                        self.logger.warning(f"â° Subtitle download attempt {sub_attempt + 1} failed: {e}")
                        continue
                    else:
                        self.logger.error(f"âŒ Subtitle download failed after {max_retries} attempts: {e}")
                        subtitle_content = None
                        break
            
            # è§£æå­—å¹•æ–‡ä»¶å†…å®¹
            if subtitle_content:
                try:
                    import json
                    subtitle_data = json.loads(subtitle_content)
                    
                    # æ ¹æ®å®é™…æ ¼å¼è§£æå­—å¹•æ•°æ®
                    if isinstance(subtitle_data, list):
                        for item in subtitle_data:
                            start_ms = None
                            end_ms = None
                            text = None
                            
                            if isinstance(item, dict):
                                # MiniMaxæ ¼å¼: {time_begin: ms, time_end: ms, text: "..."}
                                if 'time_begin' in item and 'time_end' in item and 'text' in item:
                                    start_ms = float(item['time_begin'])
                                    end_ms = float(item['time_end'])
                                    text = item['text'].strip()
                                # é€šç”¨æ ¼å¼1: {start: ms, end: ms, text: "..."}
                                elif 'start' in item and 'end' in item and 'text' in item:
                                    start_ms = float(item['start'])
                                    end_ms = float(item['end'])
                                    text = item['text'].strip()
                                # é€šç”¨æ ¼å¼2: {begin_time: ms, end_time: ms, text: "..."}
                                elif 'begin_time' in item and 'end_time' in item and 'text' in item:
                                    start_ms = float(item['begin_time'])
                                    end_ms = float(item['end_time'])
                                    text = item['text'].strip()
                                
                                if start_ms is not None and end_ms is not None and text and end_ms > start_ms:
                                    subtitle = AudioSubtitle(
                                        text=text,
                                        start_time=start_ms / 1000.0,  # è½¬æ¢ä¸ºç§’
                                        end_time=end_ms / 1000.0,      # è½¬æ¢ä¸ºç§’
                                        duration=(end_ms - start_ms) / 1000.0
                                    )
                                    subtitles.append(subtitle)
                                    self.logger.debug(f"Added subtitle: {start_ms/1000.0:.2f}s-{end_ms/1000.0:.2f}s: {text[:30]}...")
                    
                    self.logger.info(f"Successfully processed {len(subtitles)} subtitle segments from MiniMax")
                    
                except Exception as parse_error:
                    self.logger.warning(f"Failed to parse MiniMax subtitle file: {parse_error}")
            else:
                self.logger.warning("Failed to download subtitle file after retries")
        else:
            self.logger.info("No subtitle file URL returned by MiniMax")
        
        # è·å–å®é™…éŸ³é¢‘æ—¶é•¿ï¼ˆä»extra_infoæˆ–FFprobeï¼‰
        actual_duration = result.get('extra_info', {}).get('audio_length', 0) / 1000.0
        if actual_duration == 0:
            # ä½¿ç”¨FFprobeè·å–å®é™…æ—¶é•¿
            actual_duration = self._get_actual_audio_duration_from_data(audio_data)
            if actual_duration == 0:
                # æœ€åå¤‡ç”¨ä¼°ç®—
                char_count = len(request.text)
                actual_duration = (char_count / 5.0) / request.speed
        
        return GeneratedAudio(
            audio_data=audio_data,
            text=request.text,
            language=request.language,
            voice_id=voice_id,
            duration_seconds=actual_duration,
            file_size=len(audio_data),
            provider='minimax',
            format='mp3',
            generation_time=time.time() - start_time,
            subtitles=subtitles if subtitles else None
        )

    async def _generate_with_azure(self, request: AudioGenerationRequest) -> GeneratedAudio:
        """ä½¿ç”¨Azure TTSç”ŸæˆéŸ³é¢‘"""
        start_time = time.time()
        
        # è·å–è¯­éŸ³é…ç½®
        voice_config = self.voice_configs['azure'].get(request.language, self.voice_configs['azure']['zh'])
        voice_id = request.voice_id or voice_config['voice_id']
        
        # æ„å»ºSSML
        ssml = f'''<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="{request.language}">
    <voice name="{voice_id}">
        <mstts:express-as style="{voice_config.get('style', 'newscast')}" role="{voice_config.get('role', 'narrator')}">
            <prosody rate="{request.speed}" volume="{request.volume}">
                {request.text}
            </prosody>
        </mstts:express-as>
    </voice>
</speak>'''
        
        # Azure TTS API
        api_url = f"https://{self._get_azure_region()}.tts.speech.microsoft.com/cognitiveservices/v1"
        
        headers = {
            'Ocp-Apim-Subscription-Key': self.api_keys['azure'],
            'Content-Type': 'application/ssml+xml',
            'X-Microsoft-OutputFormat': 'audio-24khz-48kbitrate-mono-mp3',
            'User-Agent': 'story_generator'
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(api_url, data=ssml.encode('utf-8'), headers=headers) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"Azure TTS API error {response.status}: {error_text}")
                
                audio_data = await response.read()
                
                # ä¼°ç®—éŸ³é¢‘æ—¶é•¿ï¼ˆåŸºäºæ–‡æœ¬é•¿åº¦å’Œè¯­é€Ÿï¼‰
                char_count = len(request.text)
                estimated_duration = (char_count / 5.0) / request.speed  # å¤§çº¦5ä¸ªå­—ç¬¦/ç§’
                
                return GeneratedAudio(
                    audio_data=audio_data,
                    text=request.text,
                    language=request.language,
                    voice_id=voice_id,
                    duration_seconds=estimated_duration,
                    file_size=len(audio_data),
                    provider='azure',
                    format='mp3',
                    generation_time=time.time() - start_time
                )
    
    async def _generate_with_elevenlabs(self, request: AudioGenerationRequest) -> GeneratedAudio:
        """ä½¿ç”¨ElevenLabsç”ŸæˆéŸ³é¢‘ + Forced Alignmentå­—å¹•"""
        start_time = time.time()
        
        if not self.elevenlabs_client:
            raise Exception("ElevenLabs client not available. Please install elevenlabs package.")
        
        # è·å–è¯­éŸ³ID
        voice_config = self.voice_configs['elevenlabs'].get(request.language, self.voice_configs['elevenlabs']['en'])
        voice_id = request.voice_id or voice_config['voice_id']
        
        try:
            # Step 1: ç”ŸæˆéŸ³é¢‘
            self.logger.info(f"Generating audio with ElevenLabs voice: {voice_id}")
            
            # ä½¿ç”¨ElevenLabs SDKç”ŸæˆéŸ³é¢‘
            audio_response = self.elevenlabs_client.text_to_speech.convert(
                voice_id=voice_id,
                text=request.text,
                model_id="eleven_multilingual_v2"
            )
            
            # æ”¶é›†éŸ³é¢‘æ•°æ®
            audio_data = b""
            for chunk in audio_response:
                audio_data += chunk
            
            self.logger.info(f"ElevenLabs TTS completed: {len(audio_data)} bytes")
            
            # Step 2: ä¿å­˜ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ç”¨äºForced Alignment
            temp_audio_path = self.file_manager.get_temp_path('audio', f'elevenlabs_temp_{int(time.time())}.mp3')
            with open(temp_audio_path, 'wb') as f:
                f.write(audio_data)
            
            # Step 3: ä½¿ç”¨Forced Alignmentè·å–ç²¾ç¡®æ—¶é—´æˆ³
            subtitles = []
            try:
                self.logger.info("Running ElevenLabs Forced Alignment...")
                
                with open(temp_audio_path, 'rb') as f:
                    audio_file = BytesIO(f.read())
                
                # è°ƒç”¨Forced Alignment API
                transcription = self.elevenlabs_client.forced_alignment.create(
                    file=audio_file,
                    text=request.text
                )
                
                # è§£ææ—¶é—´æˆ³
                if hasattr(transcription, 'words') and transcription.words:
                    self.logger.info(f"Received {len(transcription.words)} word alignments")
                    
                    # æŒ‰å¥å­åˆ†ç»„å•è¯
                    current_sentence = ""
                    sentence_start = 0.0
                    sentence_end = 0.0
                    
                    for word_info in transcription.words:
                        current_sentence += word_info.text + " "
                        sentence_end = word_info.end
                        
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å¥å­ç»“æŸ
                        if word_info.text.strip().endswith(('.', '!', '?', 'ã€‚', 'ï¼', 'ï¼Ÿ')):
                            subtitle = AudioSubtitle(
                                text=current_sentence.strip(),
                                start_time=sentence_start,
                                end_time=sentence_end,
                                duration=sentence_end - sentence_start
                            )
                            subtitles.append(subtitle)
                            current_sentence = ""
                            sentence_start = sentence_end
                    
                    # å¤„ç†å‰©ä½™æ–‡æœ¬
                    if current_sentence.strip():
                        subtitle = AudioSubtitle(
                            text=current_sentence.strip(),
                            start_time=sentence_start,
                            end_time=sentence_end,
                            duration=sentence_end - sentence_start
                        )
                        subtitles.append(subtitle)
                        
                else:
                    self.logger.warning("No word alignments received from ElevenLabs")
                    
            except Exception as alignment_error:
                self.logger.warning(f"Forced Alignment failed: {alignment_error}, using estimated timing")
            
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(temp_audio_path)
                except:
                    pass
            
            # Step 4: è·å–å®é™…éŸ³é¢‘æ—¶é•¿
            actual_duration = self._get_actual_audio_duration_from_data(audio_data)
            if actual_duration == 0:
                # å¤‡ç”¨ä¼°ç®—
                char_count = len(request.text)
                actual_duration = (char_count / 5.0) / request.speed
            
            return GeneratedAudio(
                audio_data=audio_data,
                text=request.text,
                language=request.language,
                voice_id=voice_id,
                duration_seconds=actual_duration,
                file_size=len(audio_data),
                provider='elevenlabs',
                format='mp3',
                generation_time=time.time() - start_time,
                subtitles=subtitles if subtitles else None
            )
            
        except Exception as e:
            self.logger.error(f"ElevenLabs generation failed: {e}")
            raise
    
    async def _generate_with_openai(self, request: AudioGenerationRequest) -> GeneratedAudio:
        """ä½¿ç”¨OpenAI TTSç”ŸæˆéŸ³é¢‘"""
        start_time = time.time()
        
        # OpenAI TTS API
        api_url = f"{self.config.get_llm_config('script_generation').api_base}/audio/speech"
        
        voice_id = request.voice_id or 'alloy'
        
        payload = {
            "model": "tts-1",
            "input": request.text,
            "voice": voice_id,
            "response_format": "mp3",
            "speed": request.speed
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_keys['openai']}",
            "Content-Type": "application/json"
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(api_url, json=payload, headers=headers) as response:
                if response.status != 200:
                    error_text = await response.text()
                    raise Exception(f"OpenAI TTS API error {response.status}: {error_text}")
                
                audio_data = await response.read()
                
                # ä¼°ç®—éŸ³é¢‘æ—¶é•¿
                char_count = len(request.text)
                estimated_duration = (char_count / 5.0) / request.speed
                
                return GeneratedAudio(
                    audio_data=audio_data,
                    text=request.text,
                    language=request.language,
                    voice_id=voice_id,
                    duration_seconds=estimated_duration,
                    file_size=len(audio_data),
                    provider='openai',
                    format='mp3',
                    generation_time=time.time() - start_time
                )
    
    def _get_azure_region(self) -> str:
        """è·å–AzureåŒºåŸŸ"""
        # å¯ä»¥ä»é…ç½®ä¸­è¯»å–ï¼Œé»˜è®¤ä½¿ç”¨eastus
        return self.config.get('media.audio.azure_region', 'eastus')
    
    
    def generate_audio_sync(self, request: AudioGenerationRequest, 
                           provider: Optional[str] = None) -> GeneratedAudio:
        """
        åŒæ­¥ç”ŸæˆéŸ³é¢‘ï¼ˆå¯¹å¼‚æ­¥æ–¹æ³•çš„åŒ…è£…ï¼‰
        
        Args:
            request: éŸ³é¢‘ç”Ÿæˆè¯·æ±‚
            provider: æŒ‡å®šæä¾›å•†ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            GeneratedAudio: ç”Ÿæˆçš„éŸ³é¢‘
        """
        return asyncio.run(self.generate_audio_async(request, provider))
    
    async def batch_generate_audio(self, requests: List[AudioGenerationRequest], 
                                 max_concurrent: int = 3, provider: Optional[str] = None) -> List[Optional[GeneratedAudio]]:
        """
        æ‰¹é‡ç”ŸæˆéŸ³é¢‘
        
        Args:
            requests: éŸ³é¢‘ç”Ÿæˆè¯·æ±‚åˆ—è¡¨
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
        
        Returns:
            List[GeneratedAudio]: ç”Ÿæˆçš„éŸ³é¢‘åˆ—è¡¨
        """
        self.logger.info(f"Starting batch audio generation: {len(requests)} requests")
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def generate_with_semaphore(request: AudioGenerationRequest) -> GeneratedAudio:
            async with semaphore:
                return await self.generate_audio_async(request, provider)
        
        # æ‰§è¡Œå¹¶å‘ç”Ÿæˆ
        tasks = [generate_with_semaphore(request) for request in requests]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœå’Œå¼‚å¸¸ï¼šæŒ‰è¾“å…¥é¡ºåºè¿”å›ï¼Œå¤±è´¥ç”¨Noneå ä½
        ordered_results: List[Optional[GeneratedAudio]] = []
        failed_count = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                self.logger.error(f"Batch audio generation failed for request {i}: {result}")
                ordered_results.append(None)
                failed_count += 1
            else:
                ordered_results.append(result)
        
        self.logger.info(f"Batch audio generation completed: {len(requests) - failed_count} successful, {failed_count} failed")
        
        return ordered_results
    
    def save_audio(self, audio: GeneratedAudio, output_dir: Optional[str] = None, 
                   filename: Optional[str] = None) -> str:
        """
        ä¿å­˜ç”Ÿæˆçš„éŸ³é¢‘åˆ°æ–‡ä»¶
        
        Args:
            audio: ç”Ÿæˆçš„éŸ³é¢‘
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
            filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
        
        Returns:
            str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        try:
            # ç”Ÿæˆæ–‡ä»¶å
            if not filename:
                filename = self.file_manager.generate_filename(
                    content=audio.text,
                    prefix=f"audio_{audio.provider}",
                    extension=audio.format
                )
            
            # ç¡®å®šè¾“å‡ºè·¯å¾„
            if output_dir:
                filepath = Path(output_dir) / filename
            else:
                filepath = self.file_manager.get_output_path('audio', filename)
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            filepath.parent.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            with open(filepath, 'wb') as f:
                f.write(audio.audio_data)
            
            self.logger.info(f"Saved audio to: {filepath}")
            return str(filepath)
            
        except Exception as e:
            self.logger.error(f"Failed to save audio: {e}")
            raise
    
    def split_text_for_tts(self, text: str, max_length: int = 500) -> List[str]:
        """
        å°†é•¿æ–‡æœ¬åˆ†å‰²ä¸ºé€‚åˆTTSçš„çŸ­æ®µ
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            max_length: æœ€å¤§æ®µè½é•¿åº¦
        
        Returns:
            List[str]: åˆ†å‰²åçš„æ–‡æœ¬æ®µè½
        """
        if len(text) <= max_length:
            return [text]
        
        segments = []
        current_segment = ""
        
        # æŒ‰å¥å­åˆ†å‰²
        sentences = text.replace('ã€‚', 'ã€‚\n').replace('ï¼', 'ï¼\n').replace('ï¼Ÿ', 'ï¼Ÿ\n').split('\n')
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            if len(current_segment) + len(sentence) <= max_length:
                current_segment += sentence
            else:
                if current_segment:
                    segments.append(current_segment)
                current_segment = sentence
        
        if current_segment:
            segments.append(current_segment)
        
        return segments
    
    def get_generation_stats(self) -> Dict[str, Any]:
        """è·å–éŸ³é¢‘ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        # ç¼“å­˜å·²åˆ é™¤
        
        return {
            'providers': {
                'primary': self.primary_provider,
                # fallbackæœºåˆ¶å·²ç§»é™¤
                'available_keys': [k for k, v in self.api_keys.items() if v]
            },
            # ç¼“å­˜å·²åˆ é™¤
            'config': {
                'voice_speed': self.audio_config.get('voice_speed', 1.2),
                'voice_volume': self.audio_config.get('voice_volume', 1.0),
                'default_voice_id': self.default_voice_id
            }
        }
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"AudioGenerator(primary={self.primary_provider})"