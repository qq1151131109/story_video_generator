"""
åª’ä½“ç”Ÿæˆæµæ°´çº¿ - æ•´åˆå›¾åƒå’ŒéŸ³é¢‘ç”Ÿæˆ
"""
import asyncio
import time
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import logging
from dataclasses import dataclass

from core.config_manager import ConfigManager
from utils.file_manager import FileManager
from content.scene_splitter import Scene, SceneSplitResult
from content.character_analyzer import Character, CharacterAnalysisResult
from media.image_generator import ImageGenerator, ImageGenerationRequest, GeneratedImage
from media.audio_generator import AudioGenerator, AudioGenerationRequest, GeneratedAudio
from media.text_to_video_generator import TextToVideoGenerator, TextToVideoRequest, TextToVideoResult

@dataclass
class MediaGenerationRequest:
    """åª’ä½“ç”Ÿæˆæµæ°´çº¿è¯·æ±‚"""
    scenes: List[Scene]              # åœºæ™¯åˆ—è¡¨
    characters: List[Character]      # è§’è‰²åˆ—è¡¨
    main_character: Optional[Character]  # ä¸»è§’
    language: str                    # è¯­è¨€ä»£ç 
    script_title: str               # æ–‡æ¡ˆæ ‡é¢˜
    full_script: str                # å®Œæ•´æ–‡æ¡ˆ
    audio_segments: Optional[List[Dict[str, Any]]] = None  # éŸ³é¢‘ç‰‡æ®µä¿¡æ¯ï¼ˆæ–°å¢ï¼‰

@dataclass
class SceneMedia:
    """åœºæ™¯åª’ä½“èµ„æº"""
    scene: Scene                     # åœºæ™¯ä¿¡æ¯
    image: Optional[GeneratedImage] = None           # åœºæ™¯å›¾åƒï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰
    audio: Optional[GeneratedAudio] = None           # åœºæ™¯éŸ³é¢‘
    video: Optional[TextToVideoResult] = None        # ä¸€ä½“åŒ–è§†é¢‘ï¼ˆæ–°æ¨¡å¼ï¼‰
    
@dataclass
class MediaGenerationResult:
    """åª’ä½“ç”Ÿæˆæµæ°´çº¿ç»“æœ"""
    scene_media: List[SceneMedia]    # åœºæ™¯åª’ä½“åˆ—è¡¨
    character_images: Dict[str, GeneratedImage]  # è§’è‰²å›¾åƒ
    title_audio: Optional[GeneratedAudio]  # æ ‡é¢˜éŸ³é¢‘
    background_music_path: Optional[str]   # èƒŒæ™¯éŸ³ä¹è·¯å¾„
    total_processing_time: float     # æ€»å¤„ç†æ—¶é—´
    request: MediaGenerationRequest  # åŸå§‹è¯·æ±‚

class MediaPipeline:
    """
    åª’ä½“ç”Ÿæˆæµæ°´çº¿
    
    åŠŸèƒ½ï¼š
    1. ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆå›¾åƒå’ŒéŸ³é¢‘
    2. ä¸ºä¸»è¦è§’è‰²ç”Ÿæˆå›¾åƒ  
    3. ç”Ÿæˆæ ‡é¢˜éŸ³é¢‘
    4. å¤„ç†èƒŒæ™¯éŸ³ä¹
    """
    
    def __init__(self, config_manager: ConfigManager, 
                 file_manager: FileManager):
        self.config = config_manager
        self.file_manager = file_manager
        self.logger = logging.getLogger('story_generator.media')
        
        # åˆå§‹åŒ–ç”Ÿæˆå™¨
        self.image_generator = ImageGenerator(config_manager, file_manager)
        self.audio_generator = AudioGenerator(config_manager, file_manager)
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ä¸€ä½“åŒ–æ–‡ç”Ÿè§†é¢‘
        self.enable_integrated_generation = self._check_integrated_generation_support()
        
        if self.enable_integrated_generation:
            try:
                self.text_to_video_generator = TextToVideoGenerator(config_manager, file_manager)
                self.logger.info("TextToVideoGenerator initialized successfully")
            except Exception as e:
                raise RuntimeError(f"TextToVideoGenerator initialization failed: {e}. Please check RunningHub API configuration.")
        else:
            raise RuntimeError("Integrated generation is disabled. Please enable 'media.enable_integrated_generation' in configuration.")
        
        # è·å–é…ç½®
        self.media_config = config_manager.get('media', {})
        self.image_config = self.media_config.get('image', {})
        self.audio_config = self.media_config.get('audio', {})
        
        generation_mode = "integrated text-to-video" if self.enable_integrated_generation else "traditional image+audio"
        self.logger.info(f"Media pipeline initialized with {generation_mode} generation")
    
    def _check_integrated_generation_support(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ”¯æŒä¸€ä½“åŒ–æ–‡ç”Ÿè§†é¢‘ç”Ÿæˆ"""
        try:
            # æ£€æŸ¥RunningHub APIå¯†é’¥
            runninghub_key = self.config.get_api_key('runninghub')
            if not runninghub_key:
                self.logger.info("RunningHub API key not configured, using traditional mode")
                return False
            
            # æ£€æŸ¥é…ç½®ä¸­æ˜¯å¦å¯ç”¨ä¸€ä½“åŒ–æ¨¡å¼
            enable_integrated = self.config.get('media.enable_integrated_generation', True)
            if not enable_integrated:
                self.logger.info("Integrated generation disabled in configuration")
                return False
            
            self.logger.info("Integrated text-to-video generation enabled")
            return True
            
        except Exception as e:
            self.logger.warning(f"Error checking integrated generation support: {e}")
            return False
    
    async def generate_media_async(self, request: MediaGenerationRequest) -> MediaGenerationResult:
        """
        å¼‚æ­¥åª’ä½“ç”Ÿæˆæµæ°´çº¿
        
        Args:
            request: åª’ä½“ç”Ÿæˆè¯·æ±‚
        
        Returns:
            MediaGenerationResult: ç”Ÿæˆç»“æœ
        """
        start_time = time.time()
        
        try:
            self.logger.info(f"Starting media generation pipeline: {len(request.scenes)} scenes, {len(request.characters)} characters")
            
            # å¹¶è¡Œä»»åŠ¡åˆ—è¡¨
            tasks = []
            
            # ä»»åŠ¡1ï¼šç”Ÿæˆåœºæ™¯åª’ä½“ï¼ˆä¸€ä½“åŒ–æ–‡ç”Ÿè§†é¢‘æ¨¡å¼ï¼‰
            scene_task = self._generate_integrated_scene_media(
                request.scenes, 
                request.language, 
                request.audio_segments  # ä¼ é€’éŸ³é¢‘ç‰‡æ®µä¿¡æ¯
            )
            tasks.append(('scenes', scene_task))
            
            # ä»»åŠ¡2ï¼šç”Ÿæˆè§’è‰²å›¾åƒ
            if request.characters:
                character_task = self._generate_character_images(request.characters, request.language)
                tasks.append(('characters', character_task))
            
            # ä»»åŠ¡3ï¼šç”Ÿæˆæ ‡é¢˜éŸ³é¢‘
            if request.script_title:
                title_task = self._generate_title_audio(request.script_title, request.language)
                tasks.append(('title', title_task))
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            self.logger.info("Executing media generation tasks in parallel...")
            results = await asyncio.gather(*[task[1] for task in tasks], return_exceptions=True)
            
            # å¤„ç†ç»“æœ
            scene_media = []
            character_images = {}
            title_audio = None
            
            for i, (task_type, result) in enumerate(zip([task[0] for task in tasks], results)):
                if isinstance(result, Exception):
                    self.logger.error(f"Media generation task '{task_type}' failed: {result}")
                    if task_type == 'scenes':
                        raise result  # åœºæ™¯åª’ä½“æ˜¯å¿…éœ€çš„
                    continue
                
                if task_type == 'scenes':
                    scene_media = result
                elif task_type == 'characters':
                    character_images = result
                elif task_type == 'title':
                    title_audio = result
            
            # å¤„ç†èƒŒæ™¯éŸ³ä¹ï¼ˆå¦‚æœéœ€è¦ï¼‰
            background_music_path = await self._prepare_background_music(request)
            
            # åˆ›å»ºç»“æœå¯¹è±¡
            total_time = time.time() - start_time
            result = MediaGenerationResult(
                scene_media=scene_media,
                character_images=character_images,
                title_audio=title_audio,
                background_music_path=background_music_path,
                total_processing_time=total_time,
                request=request
            )
            
            self.logger.info(f"Media generation completed in {total_time:.2f}s")
            self.logger.info(f"Generated: {len(scene_media)} scene media, {len(character_images)} character images")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            self.logger.error(f"Media generation pipeline failed after {processing_time:.2f}s: {e}")
            raise
    
    async def _generate_scene_media(self, scenes: List[Scene], language: str) -> List[SceneMedia]:
        """ç”Ÿæˆåœºæ™¯åª’ä½“ï¼ˆä»…å›¾åƒï¼‰- éŸ³é¢‘ç”±ä¸»ç¨‹åºç»Ÿä¸€ç”Ÿæˆ"""
        self.logger.info(f"Generating images for {len(scenes)} scenes...")
        
        # åªå¤„ç†å›¾åƒè¯·æ±‚ï¼Œé¿å…é‡å¤éŸ³é¢‘ç”Ÿæˆ
        image_requests = []
        
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # è·å–åŠ¨ç”»ç­–ç•¥ä»¥ç¡®å®šå›¾ç‰‡åˆ†è¾¨ç‡
        animation_strategy = self.config.get('video.animation_strategy', 'traditional')
        
        for idx, scene in enumerate(scenes, start=1):
            # å›¾åƒè¯·æ±‚ - ä½¿ç”¨è‡ªé€‚åº”åˆ†è¾¨ç‡
            prompt = scene.image_prompt if scene.image_prompt else f"å†å²åœºæ™¯ï¼š{scene.content}"
            
            # ğŸ¯ è‡ªé€‚åº”åˆ†è¾¨ç‡ï¼šæ ¹æ®åŠ¨ç”»ç­–ç•¥é€‰æ‹©åˆ†è¾¨ç‡
            width, height = self.image_generator.get_adaptive_resolution(animation_strategy)
            
            image_req = ImageGenerationRequest(
                prompt=prompt,
                style="ancient_horror",
                width=width,
                height=height,
                scene_id=f"scene_{idx}_{timestamp}"
            )
            image_requests.append((scene, image_req))
        
        # ä½¿ç”¨æ‰¹é‡ç”Ÿæˆæ–¹æ³•ï¼ˆå¸¦å¹¶å‘æ§åˆ¶ï¼‰ 
        max_concurrent = self.config.get('general.max_concurrent_tasks', 5)
        self.logger.info(f"ğŸ‡®ğŸ‡² Using {max_concurrent} concurrent image generations")
        
        # æ‰¹é‡ç”Ÿæˆå›¾åƒï¼ˆè¿”å›ä¸è¾“å…¥åŒåºï¼Œå¤±è´¥ä¸ºNoneï¼‰
        image_gen_requests = [req for _, req in image_requests]
        generated_images = await self.image_generator.batch_generate_images(
            image_gen_requests, max_concurrent, animation_strategy=animation_strategy
        )
        
        # ç»„åˆç»“æœ - åªåŒ…å«å›¾åƒï¼ŒéŸ³é¢‘ç”±ä¸»ç¨‹åºç»Ÿä¸€å¤„ç†
        scene_media = []
        
        for i, scene in enumerate(scenes):
            try:
                # åªæ£€æŸ¥å›¾åƒç”Ÿæˆæ˜¯å¦æˆåŠŸ
                image = generated_images[i] if i < len(generated_images) else None
                
                if image:
                    # ğŸ”§ SceneMediaæš‚æ—¶ä½¿ç”¨Noneä½œä¸ºaudioï¼Œé¿å…é‡å¤ç”Ÿæˆ
                    scene_media.append(SceneMedia(
                        scene=scene,
                        image=image,
                        audio=None  # éŸ³é¢‘ç”±ä¸»ç¨‹åºç»Ÿä¸€ç”Ÿæˆ
                    ))
                    self.logger.info(f"Scene {i+1} image generation successful")
                else:
                    self.logger.error(f"Scene {i+1} image generation failed")
                    
            except Exception as e:
                self.logger.error(f"Scene {i+1} media combination failed: {e}")
        
        self.logger.info(f"Generated {len(scene_media)} complete scene media out of {len(scenes)} scenes")
        return scene_media
    
    async def _generate_integrated_scene_media(self, scenes: List[Scene], language: str, 
                                             audio_segments: Optional[List[Dict[str, Any]]] = None) -> List[SceneMedia]:
        """ä½¿ç”¨ä¸€ä½“åŒ–æ–‡ç”Ÿè§†é¢‘ç”Ÿæˆåœºæ™¯åª’ä½“
        
        Args:
            scenes: åœºæ™¯åˆ—è¡¨
            language: è¯­è¨€ä»£ç 
            audio_segments: éŸ³é¢‘ç‰‡æ®µåˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{'duration': float, 'scene_id': int, ...}]
        """
        if not self.text_to_video_generator:
            raise RuntimeError("TextToVideoGenerator not available, cannot generate videos. Please check RunningHub API configuration.")
        
        if not audio_segments:
            raise RuntimeError("âŒ éŸ³é¢‘ç‰‡æ®µä¿¡æ¯æ˜¯å¿…éœ€çš„ï¼æŒ‰ç…§åŸå§‹Cozeå·¥ä½œæµï¼Œå¿…é¡»å…ˆç”ŸæˆéŸ³é¢‘ç‰‡æ®µæ¥ç¡®å®šåœºæ™¯æ—¶é•¿ï¼Œç„¶åç”Ÿæˆå¯¹åº”æ—¶é•¿çš„è§†é¢‘ã€‚")
        
        self.logger.info(f"Generating integrated text-to-videos for {len(scenes)} scenes with audio-based durations...")
        
        # æ£€æŸ¥éŸ³é¢‘ç‰‡æ®µä¸åœºæ™¯æ•°é‡æ˜¯å¦åŒ¹é…
        if len(audio_segments) != len(scenes):
            raise RuntimeError(f"éŸ³é¢‘ç‰‡æ®µæ•°é‡({len(audio_segments)})ä¸åœºæ™¯æ•°é‡({len(scenes)})ä¸åŒ¹é…")
        
        # å‡†å¤‡æ–‡ç”Ÿè§†é¢‘è¯·æ±‚
        video_requests = []
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for idx, (scene, audio_segment) in enumerate(zip(scenes, audio_segments), start=1):
            # ä½¿ç”¨åœºæ™¯çš„å›¾åƒæç¤ºè¯å’Œè§†é¢‘æç¤ºè¯
            image_prompt = scene.image_prompt if scene.image_prompt else f"å†å²åœºæ™¯ï¼š{scene.content}"
            video_prompt = scene.video_prompt if scene.video_prompt else ""
            
            # ğŸµ ä½¿ç”¨éŸ³é¢‘ç‰‡æ®µçš„å®é™…æ—¶é•¿
            scene_duration = audio_segment['duration']
            self.logger.info(f"Scene {idx} duration from audio: {scene_duration:.2f}s")
            
            # ä¸€ä½“åŒ–æ¨¡å¼å›ºå®šä½¿ç”¨720x1280åˆ†è¾¨ç‡ï¼ˆå·¥ä½œæµä¼˜åŒ–åˆ†è¾¨ç‡ï¼‰
            video_req = TextToVideoRequest(
                image_prompt=image_prompt,   # æ–‡ç”Ÿå›¾æç¤ºè¯ (åœºæ™¯æè¿°)
                video_prompt=video_prompt,   # å›¾ç”Ÿè§†é¢‘æç¤ºè¯ (åŠ¨ä½œæè¿°) 
                negative_prompt="blurry, low quality, distorted, bad anatomy",
                width=720,
                height=1280,
                fps=31,
                duration=scene_duration,  # ğŸµ ä½¿ç”¨éŸ³é¢‘å®é™…æ—¶é•¿
                style="ancient_horror",
                scene_id=f"scene_{idx}_{timestamp}"
            )
            video_requests.append((scene, video_req))
        
        # ä½¿ç”¨æ‰¹é‡ç”Ÿæˆæ–¹æ³•ï¼ˆå¸¦å¹¶å‘æ§åˆ¶ï¼‰
        # âœ… ç»Ÿä¸€å¹¶å‘æ§åˆ¶ï¼šä¸å›¾åƒç”Ÿæˆä½¿ç”¨ç›¸åŒçš„é…ç½®
        max_concurrent = self.config.get('general.max_concurrent_tasks', 5)
        # æœ€å°ä¿éšœï¼šä¸ä½äº1ï¼Œä¸é«˜äº10ï¼ˆåˆç†èŒƒå›´ï¼‰ 
        max_concurrent = max(1, min(max_concurrent, 10))
        self.logger.info(f"ğŸš€ Using {max_concurrent} concurrent video generations (unified with image generation)")
        
        # æ‰¹é‡ç”Ÿæˆä¸€ä½“åŒ–è§†é¢‘
        video_gen_requests = [req for _, req in video_requests]
        
        try:
            generated_videos = await self.text_to_video_generator.batch_generate_videos_v2(
                video_gen_requests, max_concurrent
            )
        except Exception as e:
            # ä¸€ä½“åŒ–è§†é¢‘ç”Ÿæˆå®Œå…¨å¤±è´¥
            error_msg = f"Integrated text-to-video generation completely failed: {e}"
            self.logger.error(error_msg)
            
            # ç»Ÿä¸€é”™è¯¯å¤„ç†ï¼Œä¸å†ä½¿ç”¨fallback
            is_network_error = "Cannot connect to host" in str(e) or "Connection" in str(e)
            
            if is_network_error:
                raise RuntimeError(f"RunningHub API connection failed. Please check:\n"
                                 f"1. Network connectivity to api.runninghub.cn\n"
                                 f"2. RunningHub API key validity\n"
                                 f"3. Firewall settings\n"
                                 f"Original error: {e}")
            else:
                raise RuntimeError(error_msg)
        
        # æ£€æŸ¥ç”Ÿæˆç»“æœ - å…è®¸éƒ¨åˆ†å¤±è´¥ï¼Œä½†æä¾›è­¦å‘Š
        successful_videos = [v for v in generated_videos if v is not None]
        failed_count = len(scenes) - len(successful_videos)
        
        if not successful_videos:
            raise RuntimeError(f"All {len(scenes)} integrated video generations failed. "
                             f"Please check RunningHub API configuration and network connectivity.")
        
        if failed_count > 0:
            success_rate = len(successful_videos) / len(scenes) * 100
            self.logger.warning(f"âš ï¸ åª’ä½“ç”Ÿæˆéƒ¨åˆ†æˆåŠŸï¼š{len(successful_videos)}/{len(scenes)} ({success_rate:.1f}%)")
            self.logger.warning(f"ğŸ’” {failed_count}ä¸ªåœºæ™¯çš„è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œæœ€ç»ˆè§†é¢‘å°†ç¼ºå°‘è¿™äº›åœºæ™¯")
            
            if success_rate < 60:
                self.logger.error("ğŸš¨ æˆåŠŸç‡è¿‡ä½ï¼Œå»ºè®®æ£€æŸ¥ï¼š")
                self.logger.error("   1. RunningHub APIå¯†é’¥å’Œç½‘ç»œè¿æ¥")
                self.logger.error("   2. é™ä½å¹¶å‘æ•°è®¾ç½®")
                self.logger.error("   3. ç®€åŒ–æ•…äº‹å†…å®¹æè¿°")
        
        # ç»„åˆç»“æœ - æ ¹æ®åŸå§‹ç´¢å¼•æ­£ç¡®æ˜ å°„æˆåŠŸçš„åœºæ™¯
        scene_media = []
        success_indices = {getattr(video, 'original_scene_index', i): video for i, video in enumerate(successful_videos)}
        
        for i, scene in enumerate(scenes):
            try:
                # æ£€æŸ¥è¿™ä¸ªåœºæ™¯ç´¢å¼•æ˜¯å¦æœ‰å¯¹åº”çš„æˆåŠŸè§†é¢‘
                if i in success_indices:
                    video_result = success_indices[i]
                else:
                    # è¿™ä¸ªåœºæ™¯çš„è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡
                    self.logger.warning(f"â­ï¸ è·³è¿‡åœºæ™¯{i+1}ï¼š'{scene.content[:30]}...' (è§†é¢‘ç”Ÿæˆå¤±è´¥)")
                    continue
                
                if video_result:
                    # ä½¿ç”¨ä¸€ä½“åŒ–è§†é¢‘ç»“æœåˆ›å»ºSceneMedia
                    scene_media.append(SceneMedia(
                        scene=scene,
                        image=None,  # ä¸€ä½“åŒ–æ¨¡å¼ä¸éœ€è¦å•ç‹¬çš„å›¾åƒ
                        audio=None,  # éŸ³é¢‘ä»ç”±ä¸»ç¨‹åºç»Ÿä¸€ç”Ÿæˆ
                        video=video_result  # ä¸€ä½“åŒ–è§†é¢‘ç»“æœ
                    ))
                    self.logger.info(f"Scene {i+1} integrated video generation successful: "
                                   f"{video_result.file_size/1024:.1f}KB, {video_result.duration:.1f}s")
                else:
                    self.logger.error(f"Scene {i+1} integrated video generation failed")
                    
            except Exception as e:
                self.logger.error(f"Scene {i+1} integrated media combination failed: {e}")
        
        success_rate = len(scene_media) / len(scenes) * 100
        self.logger.info(f"Generated {len(scene_media)} integrated scene videos out of {len(scenes)} scenes ({success_rate:.1f}% success rate)")
        
        # å¦‚æœæˆåŠŸç‡å¤ªä½ï¼Œç»™å‡ºè­¦å‘Š
        if success_rate < 50:
            self.logger.warning(f"Low success rate ({success_rate:.1f}%) for integrated video generation. "
                              f"Consider checking API limits and network stability.")
        
        return scene_media
    
    
    
    
    async def _generate_character_images(self, characters: List[Character], 
                                       language: str) -> Dict[str, GeneratedImage]:
        """ç”Ÿæˆè§’è‰²å›¾åƒ - ä»…ç”Ÿæˆä¸»è§’è‰²å›¾åƒï¼ˆåŒ¹é…åŸå§‹Cozeå·¥ä½œæµè®¾è®¡ï¼‰"""
        if not characters:
            return {}
        
        # é€‰æ‹©ä¸»è§’è‰²ï¼šä¼˜å…ˆé€‰æ‹©æ ‡è®°ä¸ºä¸»è§’çš„ï¼Œå¦åˆ™é€‰æ‹©ç¬¬ä¸€ä¸ªè§’è‰²
        main_character = None
        for character in characters:
            if hasattr(character, 'is_main') and character.is_main:
                main_character = character
                break
        
        if not main_character:
            main_character = characters[0]  # é»˜è®¤ç¬¬ä¸€ä¸ªè§’è‰²ä¸ºä¸»è§’
        
        self.logger.info(f"Generating image for main character: {main_character.name}")
        
        if not main_character.image_prompt:
            self.logger.warning(f"Main character {main_character.name} has no image prompt")
            return {}
        
        # å‡†å¤‡ä¸»è§’è‰²å›¾åƒè¯·æ±‚
        media_config = self.config.get_media_config()
        width, height = map(int, media_config.image_resolution.split('x'))
        
        request = ImageGenerationRequest(
            prompt=main_character.image_prompt,
            style="ancient_horror",
            width=width,
            height=height
        )
        
        # ç”Ÿæˆä¸»è§’è‰²å›¾åƒ
        try:
            generated_images = await self.image_generator.batch_generate_images(
                [request], max_concurrent=1
            )
            
            if generated_images and generated_images[0]:
                character_images = {main_character.name: generated_images[0]}
                self.logger.info(f"Main character image generated: {main_character.name}")
                return character_images
            else:
                self.logger.error(f"Main character image generation failed: {main_character.name}")
                return {}
                
        except Exception as e:
            self.logger.error(f"Main character image generation error: {e}")
            return {}
    
    
    async def _generate_title_audio(self, title: str, language: str) -> GeneratedAudio:
        """ç”Ÿæˆæ ‡é¢˜éŸ³é¢‘"""
        self.logger.info(f"Generating title audio: {title}")
        
        # è·å–ä¸»è¦éŸ³é¢‘æä¾›å•†
        primary_provider = self.audio_config.get('primary_provider', 'minimax')
        
        # æ ¹æ®æä¾›å•†é€‰æ‹©voice_id
        if primary_provider == 'minimax':
            voice_id = self.audio_config.get('minimax_voice', 'male-qn-qingse')
        else:
            voice_id = self.audio_config.get('voice_id', 'pNInz6obpgDQGcFmaJgB')
        
        request = AudioGenerationRequest(
            text=title,
            language=language,
            voice_id=voice_id,
            speed=self.audio_config.get('voice_speed', 1.2),
            volume=self.audio_config.get('voice_volume', 1.0)
        )
        
        return await self.audio_generator.generate_audio_async(request, provider=primary_provider)
    
    async def _prepare_background_music(self, request: MediaGenerationRequest) -> Optional[str]:
        """å‡†å¤‡èƒŒæ™¯éŸ³ä¹"""
        # è¿™é‡Œå¯ä»¥å®ç°èƒŒæ™¯éŸ³ä¹çš„å¤„ç†é€»è¾‘
        # ä¾‹å¦‚ä»é¢„è®¾éŸ³ä¹åº“ä¸­é€‰æ‹©åˆé€‚çš„èƒŒæ™¯éŸ³ä¹
        # å¯¹åº”åŸå·¥ä½œæµçš„å¼€åœºéŸ³æ•ˆé…ç½®
        
        opening_sound_duration = self.audio_config.get('opening_sound_duration', 4884897)  # å¾®ç§’
        background_music_volume = self.audio_config.get('background_music_volume', 0.3)
        
        # è¿™é‡Œç®€å•è¿”å›Noneï¼Œåœ¨å®é™…å®ç°ä¸­å¯ä»¥å¤„ç†èƒŒæ™¯éŸ³ä¹æ–‡ä»¶
        return None
    
    def generate_media_sync(self, request: MediaGenerationRequest) -> MediaGenerationResult:
        """
        åŒæ­¥åª’ä½“ç”Ÿæˆæµæ°´çº¿ï¼ˆå¯¹å¼‚æ­¥æ–¹æ³•çš„åŒ…è£…ï¼‰
        
        Args:
            request: åª’ä½“ç”Ÿæˆè¯·æ±‚
        
        Returns:
            MediaGenerationResult: ç”Ÿæˆç»“æœ
        """
        return asyncio.run(self.generate_media_async(request))
    
    async def batch_generate_media(self, requests: List[MediaGenerationRequest], 
                                 max_concurrent: int = 5) -> List[MediaGenerationResult]:
        """
        æ‰¹é‡åª’ä½“ç”Ÿæˆ
        
        Args:
            requests: åª’ä½“ç”Ÿæˆè¯·æ±‚åˆ—è¡¨
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
        
        Returns:
            List[MediaGenerationResult]: ç”Ÿæˆç»“æœåˆ—è¡¨
        """
        self.logger.info(f"Starting batch media generation: {len(requests)} requests")
        
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def generate_with_semaphore(request: MediaGenerationRequest) -> MediaGenerationResult:
            async with semaphore:
                return await self.generate_media_async(request)
        
        # æ‰§è¡Œå¹¶å‘ç”Ÿæˆ
        tasks = [generate_with_semaphore(request) for request in requests]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœå’Œå¼‚å¸¸
        successful_results = []
        failed_count = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                self.logger.error(f"Batch media generation failed for request {i}: {result}")
                failed_count += 1
            else:
                successful_results.append(result)
        
        self.logger.info(f"Batch media generation completed: {len(successful_results)} successful, {failed_count} failed")
        
        return successful_results
    
    def save_media_files(self, result: MediaGenerationResult, output_dir: Optional[str] = None) -> Dict[str, Any]:
        """
        ä¿å­˜æ‰€æœ‰åª’ä½“æ–‡ä»¶
        
        Args:
            result: åª’ä½“ç”Ÿæˆç»“æœ
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            Dict[str, Any]: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ä¿¡æ¯
        """
        saved_files = {
            'scene_images': [],
            'scene_audio': [],
            'character_images': {},
            'title_audio': None,
            'manifest': None
        }
        
        try:
            # ä¿å­˜åœºæ™¯åª’ä½“
            for i, scene_media in enumerate(result.scene_media):
                # ä¿å­˜åœºæ™¯å›¾åƒ
                image_path = self.image_generator.save_image(
                    scene_media.image, 
                    output_dir, 
                    f"scene_{i+1:02d}_image.png"
                )
                saved_files['scene_images'].append(image_path)
                
                # ä¿å­˜åœºæ™¯éŸ³é¢‘
                audio_path = self.audio_generator.save_audio(
                    scene_media.audio,
                    output_dir,
                    f"scene_{i+1:02d}_audio.mp3"
                )
                saved_files['scene_audio'].append(audio_path)
            
            # ä¿å­˜è§’è‰²å›¾åƒ
            for char_name, char_image in result.character_images.items():
                char_path = self.image_generator.save_image(
                    char_image,
                    output_dir,
                    f"character_{char_name.replace(' ', '_')}.png"
                )
                saved_files['character_images'][char_name] = char_path
            
            # ä¿å­˜æ ‡é¢˜éŸ³é¢‘
            if result.title_audio:
                title_path = self.audio_generator.save_audio(
                    result.title_audio,
                    output_dir,
                    "title_audio.mp3"
                )
                saved_files['title_audio'] = title_path
            
            # ä¿å­˜åª’ä½“æ¸…å•
            manifest_data = {
                'metadata': {
                    'language': result.request.language,
                    'scene_count': len(result.scene_media),
                    'character_count': len(result.character_images),
                    'total_processing_time': result.total_processing_time,
                    'created_at': time.strftime('%Y-%m-%d %H:%M:%S')
                },
                'scenes': [
                    {
                        'sequence': sm.scene.sequence,
                        'duration': sm.scene.duration_seconds,
                        'image_file': Path(saved_files['scene_images'][i]).name,
                        'audio_file': Path(saved_files['scene_audio'][i]).name,
                        'image_size': sm.image.file_size,
                        'audio_size': sm.audio.file_size
                    }
                    for i, sm in enumerate(result.scene_media)
                ],
                'characters': [
                    {
                        'name': char_name,
                        'image_file': Path(image_path).name,
                        'image_size': result.character_images[char_name].file_size
                    }
                    for char_name, image_path in saved_files['character_images'].items()
                ]
            }
            
            if not output_dir:
                manifest_filename = self.file_manager.generate_filename(
                    content=result.request.script_title,
                    prefix=f"media_manifest_{result.request.language}",
                    extension="json"
                )
                manifest_path = self.file_manager.get_output_path('manifests', manifest_filename)
            else:
                manifest_path = Path(output_dir) / f"media_manifest_{int(time.time())}.json"
            
            success = self.file_manager.save_json(manifest_data, manifest_path)
            if success:
                saved_files['manifest'] = str(manifest_path)
                self.logger.info(f"Saved media manifest to: {manifest_path}")
            
            total_files = (len(saved_files['scene_images']) + 
                          len(saved_files['scene_audio']) + 
                          len(saved_files['character_images']) +
                          (1 if saved_files['title_audio'] else 0))
            
            self.logger.info(f"Saved {total_files} media files")
            
            return saved_files
            
        except Exception as e:
            self.logger.error(f"Failed to save media files: {e}")
            return saved_files
    
    def get_pipeline_stats(self) -> Dict[str, Any]:
        """è·å–æµæ°´çº¿ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'components': {
                'image_generator': self.image_generator.get_generation_stats(),
                'audio_generator': self.audio_generator.get_generation_stats()
            },
            # ç¼“å­˜å·²åˆ é™¤
            'config': {
                'image': self.image_config,
                'audio': self.audio_config
            }
        }
    
    def estimate_costs(self, request: MediaGenerationRequest) -> Dict[str, Any]:
        """ä¼°ç®—ç”Ÿæˆæˆæœ¬"""
        # è¿™é‡Œå¯ä»¥å®ç°æˆæœ¬ä¼°ç®—é€»è¾‘
        scene_count = len(request.scenes)
        character_count = len(request.characters)
        
        # ç®€å•çš„æˆæœ¬ä¼°ç®—ç¤ºä¾‹
        estimated_costs = {
            'images': {
                'scene_images': scene_count * 0.02,  # å‡è®¾æ¯å¼ å›¾ç‰‡$0.02
                'character_images': character_count * 0.02
            },
            'audio': {
                'scene_audio': scene_count * 0.01,  # å‡è®¾æ¯æ®µéŸ³é¢‘$0.01
                'title_audio': 0.01 if request.script_title else 0
            }
        }
        
        total_cost = (sum(estimated_costs['images'].values()) + 
                     sum(estimated_costs['audio'].values()))
        
        estimated_costs['total'] = total_cost
        
        return estimated_costs
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"MediaPipeline(image_gen={self.image_generator}, audio_gen={self.audio_generator})"