#!/usr/bin/env python3
"""
LangChainå®˜æ–¹æ–¹æ¡ˆ - å½»åº•è§£å†³LLMè¾“å‡ºæ ¼å¼é²æ£’æ€§é—®é¢˜

åŒ…å«2024å¹´æœ€æ–°çš„å®˜æ–¹è§£å†³æ–¹æ¡ˆ:
1. with_structured_output() - OpenAI Strict Mode (100%æˆåŠŸç‡)
2. RetryOutputParser - æ™ºèƒ½é‡è¯•æœºåˆ¶  
3. OutputFixingParser - è‡ªåŠ¨ä¿®å¤æœºåˆ¶
4. å¤šå±‚é™çº§ç­–ç•¥
"""

import asyncio
import logging
from typing import Type, TypeVar, Any, Dict, List, Optional, Literal
from enum import Enum

# LangChainæ ¸å¿ƒç»„ä»¶
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langchain.output_parsers import RetryOutputParser, OutputFixingParser

# æ•°æ®æ¨¡å‹
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.structured_output_models import (
    SceneSplitOutput, ImagePromptOutput, CharacterAnalysisOutput, ScriptGenerationOutput
)

T = TypeVar('T', bound='BaseModel')

class ParseStrategy(Enum):
    """è§£æç­–ç•¥æšä¸¾"""
    STRUCTURED_OUTPUT = "structured_output"  # OpenAI Strict Mode (æœ€å¯é )
    RETRY_PARSER = "retry_parser"            # é‡è¯•è§£æå™¨
    OUTPUT_FIXING = "output_fixing"          # è¾“å‡ºä¿®å¤è§£æå™¨  
    TRADITIONAL = "traditional"              # ä¼ ç»Ÿè§£ææ–¹æ³•

class LangChainOfficialSolution:
    """
    LangChainå®˜æ–¹è§£å†³æ–¹æ¡ˆ - 2024å¹´æœ€å¼ºçš„LLMè¾“å‡ºæ ¼å¼é²æ£’æ€§æ–¹æ¡ˆ
    
    ç‰¹ç‚¹:
    1. ä¼˜å…ˆä½¿ç”¨OpenAI Structured Output (strict=True) - 100%æˆåŠŸç‡
    2. è‡ªåŠ¨é™çº§åˆ°RetryOutputParserå’ŒOutputFixingParser  
    3. æ”¯æŒå¤šç§LLMæä¾›å•†
    4. å®Œå…¨åŸºäºLangChainå®˜æ–¹å®ç°
    """
    
    def __init__(self, 
                 openai_api_key: Optional[str] = None,
                 fallback_llm = None,
                 max_retries: int = 3):
        """
        åˆå§‹åŒ–LangChainå®˜æ–¹è§£å†³æ–¹æ¡ˆ
        
        Args:
            openai_api_key: OpenAI APIå¯†é’¥ (ç”¨äºStructured Output)
            fallback_llm: é™çº§LLM (ç”¨äºRetryOutputParser/OutputFixingParser)
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.max_retries = max_retries
        self.logger = logging.getLogger('langchain_official_solution')
        
        # OpenAI LLM (æ”¯æŒStructured Output)
        self.openai_llm = None
        if openai_api_key:
            self.openai_llm = ChatOpenAI(
                model="gpt-4o-2024-08-06",  # æ”¯æŒStructured Outputçš„æ¨¡å‹
                api_key=openai_api_key,
                temperature=0  # ç¡®ä¿ç¨³å®šæ€§
            )
            self.logger.info("âœ… OpenAI Structured Output LLM å·²åˆå§‹åŒ–")
        
        # é™çº§LLM
        self.fallback_llm = fallback_llm
        
        # è§£æå™¨ç¼“å­˜
        self._structured_models = {}
        self._retry_parsers = {}
        self._fixing_parsers = {}
    
    def get_structured_model(self, pydantic_model: Type[T]):
        """è·å–æ”¯æŒStructured Outputçš„æ¨¡å‹"""
        if not self.openai_llm:
            return None
            
        model_name = pydantic_model.__name__
        
        if model_name not in self._structured_models:
            try:
                # ä½¿ç”¨OpenAI Structured Output (strict=True)
                structured_model = self.openai_llm.with_structured_output(
                    pydantic_model,
                    method="json_schema",  # ä½¿ç”¨æœ€æ–°çš„JSON Schemaæ–¹æ³•
                    strict=True           # å¯ç”¨ä¸¥æ ¼æ¨¡å¼ - 100%ç¬¦åˆSchema
                )
                
                self._structured_models[model_name] = structured_model
                self.logger.info(f"âœ… åˆ›å»ºStructured Outputæ¨¡å‹: {model_name} (strict=True)")
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ æ— æ³•åˆ›å»ºStructured Outputæ¨¡å‹ {model_name}: {e}")
                return None
        
        return self._structured_models[model_name]
    
    def get_retry_parser(self, pydantic_model: Type[T]) -> Optional[RetryOutputParser]:
        """è·å–é‡è¯•è§£æå™¨"""
        if not self.fallback_llm:
            return None
            
        model_name = pydantic_model.__name__
        
        if model_name not in self._retry_parsers:
            base_parser = PydanticOutputParser(pydantic_object=pydantic_model)
            retry_parser = RetryOutputParser.from_llm(
                parser=base_parser,
                llm=self.fallback_llm,
                max_retries=self.max_retries
            )
            
            self._retry_parsers[model_name] = retry_parser
            self.logger.info(f"âœ… åˆ›å»ºRetryOutputParser: {model_name}")
        
        return self._retry_parsers[model_name]
    
    def get_fixing_parser(self, pydantic_model: Type[T]) -> Optional[OutputFixingParser]:
        """è·å–ä¿®å¤è§£æå™¨"""
        if not self.fallback_llm:
            return None
            
        model_name = pydantic_model.__name__
        cache_key = f"{model_name}_fixing"
        
        if cache_key not in self._fixing_parsers:
            base_parser = PydanticOutputParser(pydantic_object=pydantic_model)
            fixing_parser = OutputFixingParser.from_llm(
                parser=base_parser,
                llm=self.fallback_llm
            )
            
            self._fixing_parsers[cache_key] = fixing_parser
            self.logger.info(f"âœ… åˆ›å»ºOutputFixingParser: {model_name}")
        
        return self._fixing_parsers[cache_key]
    
    async def generate_structured_output(self,
                                       pydantic_model: Type[T],
                                       system_prompt: str,
                                       user_prompt: str,
                                       strategy: ParseStrategy = ParseStrategy.STRUCTURED_OUTPUT) -> T:
        """
        ç”Ÿæˆç»“æ„åŒ–è¾“å‡º - ä½¿ç”¨æŒ‡å®šçš„è§£æç­–ç•¥
        
        Args:
            pydantic_model: ç›®æ ‡Pydanticæ¨¡å‹
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            user_prompt: ç”¨æˆ·æç¤ºè¯  
            strategy: è§£æç­–ç•¥
            
        Returns:
            è§£æåçš„ç»“æ„åŒ–å¯¹è±¡
        """
        
        if strategy == ParseStrategy.STRUCTURED_OUTPUT:
            return await self._generate_with_structured_output(
                pydantic_model, system_prompt, user_prompt
            )
        elif strategy == ParseStrategy.RETRY_PARSER:
            return await self._generate_with_retry_parser(
                pydantic_model, system_prompt, user_prompt
            )
        elif strategy == ParseStrategy.OUTPUT_FIXING:
            return await self._generate_with_fixing_parser(
                pydantic_model, system_prompt, user_prompt
            )
        else:
            return await self._generate_with_traditional_parsing(
                pydantic_model, system_prompt, user_prompt
            )
    
    async def generate_with_auto_fallback(self,
                                        pydantic_model: Type[T],
                                        system_prompt: str,
                                        user_prompt: str) -> T:
        """
        è‡ªåŠ¨é™çº§ç­–ç•¥ - ä»æœ€å¯é çš„æ–¹æ³•å¼€å§‹ï¼Œé€æ­¥é™çº§
        
        é™çº§é¡ºåº:
        1. OpenAI Structured Output (strict=True) - 100%æˆåŠŸç‡
        2. RetryOutputParser - æ™ºèƒ½é‡è¯•
        3. OutputFixingParser - è‡ªåŠ¨ä¿®å¤
        4. ä¼ ç»Ÿè§£æ - å…œåº•æ–¹æ¡ˆ
        """
        
        errors = []
        
        # ç­–ç•¥1: OpenAI Structured Output (æœ€å¯é )
        try:
            if self.openai_llm:
                self.logger.info("ğŸš€ å°è¯•OpenAI Structured Output (strict=True)...")
                result = await self._generate_with_structured_output(
                    pydantic_model, system_prompt, user_prompt
                )
                self.logger.info("âœ… OpenAI Structured Output æˆåŠŸ!")
                return result
        except Exception as e:
            error_msg = f"OpenAI Structured Outputå¤±è´¥: {e}"
            errors.append(error_msg)
            self.logger.warning(f"âš ï¸ {error_msg}")
        
        # ç­–ç•¥2: RetryOutputParser (æ™ºèƒ½é‡è¯•)  
        try:
            if self.fallback_llm:
                self.logger.info("ğŸ”„ é™çº§åˆ°RetryOutputParser...")
                result = await self._generate_with_retry_parser(
                    pydantic_model, system_prompt, user_prompt
                )
                self.logger.info("âœ… RetryOutputParser æˆåŠŸ!")
                return result
        except Exception as e:
            error_msg = f"RetryOutputParserå¤±è´¥: {e}"
            errors.append(error_msg)
            self.logger.warning(f"âš ï¸ {error_msg}")
        
        # ç­–ç•¥3: OutputFixingParser (è‡ªåŠ¨ä¿®å¤)
        try:
            if self.fallback_llm:
                self.logger.info("ğŸ”§ é™çº§åˆ°OutputFixingParser...")
                result = await self._generate_with_fixing_parser(
                    pydantic_model, system_prompt, user_prompt
                )
                self.logger.info("âœ… OutputFixingParser æˆåŠŸ!")
                return result
        except Exception as e:
            error_msg = f"OutputFixingParserå¤±è´¥: {e}"
            errors.append(error_msg)
            self.logger.warning(f"âš ï¸ {error_msg}")
        
        # ç­–ç•¥4: ä¼ ç»Ÿè§£æ (å…œåº•æ–¹æ¡ˆ)
        try:
            self.logger.info("ğŸ“ é™çº§åˆ°ä¼ ç»Ÿè§£ææ–¹æ³•...")
            result = await self._generate_with_traditional_parsing(
                pydantic_model, system_prompt, user_prompt
            )
            self.logger.info("âœ… ä¼ ç»Ÿè§£ææ–¹æ³•æˆåŠŸ!")
            return result
        except Exception as e:
            error_msg = f"ä¼ ç»Ÿè§£ææ–¹æ³•å¤±è´¥: {e}"
            errors.append(error_msg)
            self.logger.error(f"âŒ {error_msg}")
        
        # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥
        all_errors = "; ".join(errors)
        raise Exception(f"æ‰€æœ‰è§£æç­–ç•¥éƒ½å¤±è´¥: {all_errors}")
    
    async def _generate_with_structured_output(self, 
                                             pydantic_model: Type[T],
                                             system_prompt: str, 
                                             user_prompt: str) -> T:
        """ä½¿ç”¨OpenAI Structured Outputç”Ÿæˆ (100%æˆåŠŸç‡)"""
        structured_model = self.get_structured_model(pydantic_model)
        
        if not structured_model:
            raise Exception("OpenAI Structured Outputæ¨¡å‹æœªåˆå§‹åŒ–")
        
        # åˆ›å»ºæ¶ˆæ¯
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ]
        
        # ä½¿ç”¨Structured Output - 100%ç¬¦åˆSchema
        result = await structured_model.ainvoke(messages)
        
        return result
    
    async def _generate_with_retry_parser(self,
                                        pydantic_model: Type[T], 
                                        system_prompt: str,
                                        user_prompt: str) -> T:
        """ä½¿ç”¨RetryOutputParserç”Ÿæˆ"""
        retry_parser = self.get_retry_parser(pydantic_model)
        
        if not retry_parser:
            raise Exception("RetryOutputParseræœªåˆå§‹åŒ–")
        
        # å¢å¼ºæç¤ºè¯
        base_parser = PydanticOutputParser(pydantic_object=pydantic_model)
        format_instructions = base_parser.get_format_instructions()
        
        enhanced_system_prompt = f"""
{system_prompt}

{format_instructions}

è¾“å‡ºè¦æ±‚: å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¸¥æ ¼éµå¾ªä¸Šè¿°Schemaã€‚
"""
        
        # ç”Ÿæˆå®Œæ•´promptç”¨äºé‡è¯•ä¸Šä¸‹æ–‡
        full_prompt = f"System: {enhanced_system_prompt}\nUser: {user_prompt}"
        
        # è°ƒç”¨LLM
        messages = [
            SystemMessage(content=enhanced_system_prompt),
            HumanMessage(content=user_prompt)
        ]
        
        response = await self.fallback_llm.ainvoke(messages)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        # ä½¿ç”¨RetryOutputParserè§£æ
        from langchain_core.prompt_values import StringPromptValue
        prompt_value = StringPromptValue(text=full_prompt)
        
        result = retry_parser.parse_with_prompt(response_text, prompt_value)
        return result
    
    async def _generate_with_fixing_parser(self,
                                         pydantic_model: Type[T],
                                         system_prompt: str, 
                                         user_prompt: str) -> T:
        """ä½¿ç”¨OutputFixingParserç”Ÿæˆ"""
        fixing_parser = self.get_fixing_parser(pydantic_model)
        
        if not fixing_parser:
            raise Exception("OutputFixingParseræœªåˆå§‹åŒ–")
        
        # å¢å¼ºæç¤ºè¯
        base_parser = PydanticOutputParser(pydantic_object=pydantic_model)
        format_instructions = base_parser.get_format_instructions()
        
        enhanced_system_prompt = f"""
{system_prompt}

{format_instructions}

è¾“å‡ºè¦æ±‚: å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¸¥æ ¼éµå¾ªä¸Šè¿°Schemaã€‚
"""
        
        # è°ƒç”¨LLM
        messages = [
            SystemMessage(content=enhanced_system_prompt),
            HumanMessage(content=user_prompt)
        ]
        
        response = await self.fallback_llm.ainvoke(messages)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        # ä½¿ç”¨OutputFixingParserè§£æ
        result = fixing_parser.parse(response_text)
        return result
    
    async def _generate_with_traditional_parsing(self,
                                               pydantic_model: Type[T],
                                               system_prompt: str,
                                               user_prompt: str) -> T:
        """ä¼ ç»Ÿè§£ææ–¹æ³• (å…œåº•æ–¹æ¡ˆ)"""
        # ä½¿ç”¨æˆ‘ä»¬ä¹‹å‰å®ç°çš„é²æ£’è§£æå™¨ä½œä¸ºå…œåº•
        from robust_output_parser import RobustStructuredOutputParser
        
        parser = RobustStructuredOutputParser(pydantic_model)
        
        # å¢å¼ºæç¤ºè¯  
        base_parser = PydanticOutputParser(pydantic_object=pydantic_model)
        format_instructions = base_parser.get_format_instructions()
        
        enhanced_system_prompt = f"""
{system_prompt}

{format_instructions}

è¾“å‡ºè¦æ±‚: å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä¸¥æ ¼éµå¾ªä¸Šè¿°Schemaã€‚
"""
        
        # ä½¿ç”¨ä»»ä½•å¯ç”¨çš„LLM
        llm = self.fallback_llm or self.openai_llm
        if not llm:
            raise Exception("æ²¡æœ‰å¯ç”¨çš„LLM")
        
        messages = [
            SystemMessage(content=enhanced_system_prompt),
            HumanMessage(content=user_prompt)
        ]
        
        response = await llm.ainvoke(messages)
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        # ä½¿ç”¨é²æ£’è§£æå™¨
        result = parser.parse(response_text)
        return result


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
async def test_langchain_official_solutions():
    """æµ‹è¯•LangChainå®˜æ–¹è§£å†³æ–¹æ¡ˆ"""
    print("ğŸš€ æµ‹è¯•LangChainå®˜æ–¹è§£å†³æ–¹æ¡ˆ")
    print("=" * 70)
    
    # æ¨¡æ‹ŸLLM (å®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®çš„LLM)
    class MockLLM:
        async def ainvoke(self, messages):
            class MockResponse:
                content = '''
                {
                    "scenes": [
                        {"sequence": 1, "content": "ç§¦å§‹çš‡åˆ¶å®šç»Ÿä¸€æˆ˜ç•¥", "duration": 3.0},
                        {"sequence": 2, "content": "é›†ç»“å†›é˜Ÿå‡†å¤‡å¾æˆ˜", "duration": 3.0},
                        {"sequence": 3, "content": "æ”»å…‹éŸ©å›½é¦–éƒ½è¡ŒåŠ¨", "duration": 3.0},
                        {"sequence": 4, "content": "ç»§ç»­å¾æœå…¶ä»–è¯¸ä¾¯", "duration": 3.0},
                        {"sequence": 5, "content": "å»ºç«‹ç»Ÿä¸€çš„å¸åˆ¶", "duration": 3.0}
                    ]
                }
                '''
            return MockResponse()
    
    try:
        # åˆ›å»ºå®˜æ–¹è§£å†³æ–¹æ¡ˆå®ä¾‹ (è¿™é‡Œä½¿ç”¨æ¨¡æ‹ŸLLM)
        solution = LangChainOfficialSolution(
            # openai_api_key="your-openai-api-key",  # å®é™…ä½¿ç”¨æ—¶æä¾›çœŸå®APIå¯†é’¥
            fallback_llm=MockLLM(),
            max_retries=2
        )
        
        # æµ‹è¯•è‡ªåŠ¨é™çº§ç­–ç•¥
        print("ğŸ¯ æµ‹è¯•è‡ªåŠ¨é™çº§ç­–ç•¥...")
        result = await solution.generate_with_auto_fallback(
            pydantic_model=SceneSplitOutput,
            system_prompt="ä½ æ˜¯ä¸“ä¸šçš„æ•…äº‹åœºæ™¯åˆ†å‰²ä¸“å®¶ã€‚å°†è¾“å…¥çš„æ•…äº‹åˆ†å‰²ä¸ºå¤šä¸ªåœºæ™¯ï¼Œæ¯ä¸ªåœºæ™¯3ç§’é’Ÿã€‚",
            user_prompt="è¯·å°†ç§¦å§‹çš‡ç»Ÿä¸€å¤©ä¸‹çš„æ•…äº‹åˆ†å‰²ä¸º5ä¸ªåœºæ™¯ï¼Œæ¯ä¸ªåœºæ™¯åŒ…å«ä¸åŒçš„é‡è¦æƒ…èŠ‚ç‚¹ã€‚"
        )
        
        print(f"âœ… è‡ªåŠ¨é™çº§ç­–ç•¥æˆåŠŸ! è§£æäº† {len(result.scenes)} ä¸ªåœºæ™¯:")
        for scene in result.scenes:
            print(f"   åœºæ™¯{scene.sequence}: {scene.content}")
        
        # æµ‹è¯•ç‰¹å®šç­–ç•¥
        print("\nğŸ”§ æµ‹è¯•OutputFixingParserç­–ç•¥...")
        result2 = await solution.generate_structured_output(
            pydantic_model=SceneSplitOutput,
            system_prompt="ä½ æ˜¯ä¸“ä¸šçš„æ•…äº‹åœºæ™¯åˆ†å‰²ä¸“å®¶ã€‚",
            user_prompt="åˆ†å‰²å”å¤ªå®—è´è§‚ä¹‹æ²»çš„æ•…äº‹ä¸º5ä¸ªåœºæ™¯ã€‚",
            strategy=ParseStrategy.OUTPUT_FIXING
        )
        
        print(f"âœ… OutputFixingParserç­–ç•¥æˆåŠŸ! è§£æäº† {len(result2.scenes)} ä¸ªåœºæ™¯")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def demonstrate_all_strategies():
    """æ¼”ç¤ºæ‰€æœ‰è§£æç­–ç•¥çš„æ•ˆæœ"""
    print("\nğŸ“Š LangChainå®˜æ–¹è§£å†³æ–¹æ¡ˆ - ç­–ç•¥å¯¹æ¯”")
    print("=" * 70)
    
    strategies = [
        (ParseStrategy.STRUCTURED_OUTPUT, "OpenAI Structured Output (100%å¯é )"),
        (ParseStrategy.RETRY_PARSER, "RetryOutputParser (æ™ºèƒ½é‡è¯•)"),
        (ParseStrategy.OUTPUT_FIXING, "OutputFixingParser (è‡ªåŠ¨ä¿®å¤)"),
        (ParseStrategy.TRADITIONAL, "ä¼ ç»Ÿè§£æ (å…œåº•æ–¹æ¡ˆ)")
    ]
    
    print("ğŸ¯ å¯ç”¨ç­–ç•¥:")
    for strategy, description in strategies:
        print(f"   {strategy.value}: {description}")
    
    print("\nğŸ’¡ æ¨èä½¿ç”¨é¡ºåº (è‡ªåŠ¨é™çº§):")
    print("   1. ğŸ¥‡ OpenAI Structured Output - 100%æˆåŠŸç‡,æ”¯æŒstrictæ¨¡å¼")
    print("   2. ğŸ¥ˆ RetryOutputParser - ä½¿ç”¨åŸå§‹prompté‡æ–°ç”Ÿæˆ")  
    print("   3. ğŸ¥‰ OutputFixingParser - LLMè‡ªåŠ¨ä¿®å¤æ ¼å¼é”™è¯¯")
    print("   4. ğŸ… ä¼ ç»Ÿé²æ£’è§£æ - å¤šé‡ä¿®å¤ç­–ç•¥å…œåº•")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_langchain_official_solutions())
    
    # æ¼”ç¤ºç­–ç•¥å¯¹æ¯”  
    asyncio.run(demonstrate_all_strategies())